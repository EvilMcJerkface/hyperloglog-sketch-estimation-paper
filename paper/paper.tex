%#############################
%# Copyright 2016 Otmar Ertl #
%#############################


% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[a4paper]{scrartcl}
%\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx} % support the \includegraphics command and options
\usepackage{svg}
\usepackage{algpseudocode,algorithm,algorithmicx}
\usepackage{float}
\usepackage{url}
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...
\usepackage{hyperref}
\usepackage[capitalise,nameinlink,noabbrev]{cleveref}

% \renewcommand{\sffamily}{\rmfamily}

% SYMBOLS
\newcommand*{\symDefine}[2]{\newcommand{{#1}}{{#2}}}

\symDefine{\symPrecision}{p}
\symDefine{\symRegRange}{q}
\symDefine{\symRegVal}{k}
\symDefine{\symRegValVariate}{K}
\symDefine{\symNumReg}{m}
\symDefine{\symDataItem}{D}
\symDefine{\symBitRepA}{a}
\symDefine{\symBitRepB}{b}
\symDefine{\symIndexI}{i}
\symDefine{\symIndexK}{k}
\symDefine{\symIndexL}{l}
\symDefine{\symIndexJ}{j}
\symDefine{\symCount}{c}
\symDefine{\symAlpha}{\alpha}
\symDefine{\symBeta}{\beta}
\symDefine{\symA}{a}
\symDefine{\symB}{b}
\symDefine{\symE}{e}
\symDefine{\symX}{x}
\symDefine{\symXEstimate}{\hat{\symX}}
\symDefine{\symXNormalized}{\symX'}
\symDefine{\symN}{n}
\symDefine{\symS}{s}
\symDefine{\symY}{y}
\symDefine{\symZ}{z}
\symDefine{\symInteger}{z}
\symDefine{\symIntegerVariate}{Z}
\symDefine{\symCardinality}{n}
\symDefine{\symCardinalityEstimate}{\hat{\symCardinality}}
\symDefine{\symCardinalityOriginalEstimate}{\symCardinalityEstimate_\text{raw}}
\symDefine{\symError}{\varepsilon}
\symDefine{\symStopDelta}{\delta}
\symDefine{\symStopEpsilon}{\varepsilon}
\symDefine{\symBigO}{\mathcal{O}}
\symDefine{\symExpectation}{\mathbb{E}}
\symDefine{\symProbability}{P}
\symDefine{\symProbabilityMass}{\rho}
\symDefine{\symRegProbability}{\gamma}
\symDefine{\symNu}{\nu}
\symDefine{\symKappa}{\kappa}
\symDefine{\symLikelihood}{\mathcal{L}}
\symDefine{\symPoissonRate}{\lambda}
\symDefine{\symPoissonRateEstimate}{\hat{\symPoissonRate}}
\symDefine{\symFunc}{f}
\symDefine{\symFuncPrime}{g}
\symDefine{\symHelper}{h}
\symDefine{\symHelperApprox}{\tilde{\symHelper}}
\symDefine{\symSetA}{A}
\symDefine{\symSetB}{B}
\symDefine{\symSetS}{S}
\symDefine{\symSetX}{X}
\symDefine{\symSetASuffix}{a}
\symDefine{\symSetBSuffix}{b}
\symDefine{\symSetXSuffix}{x}
\symDefine{\symCountMatrix}{\mathbf{c}}
\symDefine{\symPowerSeriesFunc}{\xi}
\symDefine{\symSmallCorrectionFunc}{\sigma}
\symDefine{\symLargeCorrectionFunc}{\tau}
\symDefine{\symEpsPowerSeriesFunc}{\varepsilon_\symPowerSeriesFunc}

%%% END Article customizations


\title{New cardinality estimation algorithms for HyperLogLog sketches}
\subtitle{Draft version}
\author{Otmar Ertl}

\begin{document}
\maketitle
\begin{abstract}
This paper presents new methods to estimate the cardinalities of multisets recorded by HyperLogLog sketches. A theoretically founded extension to the original estimate is presented that eliminates the bias for small and large cardinalities. Based on the maximum likelihood principle another unbiased method is derived together with a robust and efficient numerical algorithm to calculate the estimate. The maximum-likelihood method is also appropriate to improve cardinality estimates of set intersections compared to the inclusion-exclusion principle. The new methods are demonstrated and verified by extensive simulations.
\end{abstract}

\section{Introduction}
Counting the number of distinct elements in a data stream or large datasets is a common problem in big data processing. Often there are parallel streams  or data is spread over a cluster, which makes this task even more challenging.
In principle, finding the number of distinct elements $\symCardinality$ with a maximum relative error $\symError$  in a data stream requires $\Omega(\symCardinality)$ space \cite{Alon1999}. However, probabilistic algorithms that achieve the requested accuracy only with high probability are able to drastically reduce space requirements. Many different probabilistic algorithms have been developed over the past two decades \cite{Metwally2008,Ting2014}. An algorithm with an optimal space complexity of $\Omega(\symError^{-2}+\log \symCardinality)$ \cite{Alon1999, Indyk2003} was finally presented \cite{Kane2010}. This algorithm, however, is not very efficient in practice \cite{Ting2014}.

Currently, the best algorithm that also works for distributed setups is the near-optimal HyperLogLog algorithm \cite{Flajolet2007} with space complexity $\Omega(\symError^{-2} \log\log\symCardinality +\log \symCardinality)$. The originally proposed estimation method has some problems to guarantee the same estimation error over the entire range of cardinalities. It was proposed to correct the estimate by empirical means \cite{Heule2013,Rhodes2015,Sanfilippo2014}. 

In case the data is not distributed and results do not need to be aggregated further, there are even more efficient estimation algorithms available. On the one hand there is the self-learning bitmap \cite{Chen2011, Chen2015}, and on the other hand there is the HyperLogLog algorithm extended by a historic inverse probability estimator that is continuously updated together with the HyperLogLog sketch \cite{Ting2014}. Both achieve the same estimation error using less space. However, the estimated cardinality depends on the insertion order of elements and hence cannot be used in a distributed environment. 

%In contrast, HyperLogLog sketches (without historic inverse probability estimator) built from different sets of elements can be merged and the result is identical to a HyperLogLog sketch obtained by inserting all elements of the union set. Therefore, the HyperLogLog sketch inherently supports cardinality estimation of unions. However, there are also applications which require the cardinality estimation of intersections.

\section{HyperLogLog data structure}
The HyperLogLog algorithm uses a sketching data structure that consists of $\symNumReg$ registers. For performance reasons the number of registers is chosen to be a power of 2: $\symNumReg = 2^\symPrecision$. $\symPrecision$ is the precision that directly influences the relative error which scales like $1/\sqrt{\symNumReg}$. All registers start with initial value 0. The HyperLogLog algorithm successively increases the register values up to a maximum value limited by the space per register which is usually between 5 and 8 bits. 

\subsection{Data element insertion}
\label{sec:data_element_insertion}
In order to insert a data element into a HyperLogLog data structure a hash value is calculated. The leading $\symPrecision$ bits of the hash value are used to select one of the $2^\symPrecision$ registers. Among the next $\symRegRange$ bits, the position of the first 1-bit is determined which is a value in the range $[1,\symRegRange+1]$. The value $\symRegRange+1$ is used, if all $\symRegRange$ bits are equal to 0. If the position of the first 1-bit exceeds the value of the selected register, the register value is replaced. \cref{alg:insert} shows the update procedure for inserting a data element into the HyperLogLog sketch.

A HyperLogLog sketch can be characterized by the parameter pair $(\symPrecision, \symRegRange)$. The first parameter controls the relative error while the second defines the possible value range of a register. A register can take all values starting from 0 to $\symRegRange+1$, inclusively. 

The number of bits of the consumed hash value $\symPrecision+\symRegRange$ limit the maximum cardinality that can be tracked. Obviously, if the cardinality reaches values in the order of $2^{\symPrecision+\symRegRange}$, hash collisions will become more apparent, which will reduce estimation accuracy drastically.

At any time a $(\symPrecision, \symRegRange)$-HyperLogLog sketch with parameters $(\symPrecision, \symRegRange)$ can be compressed into a $(\symPrecision', \symRegRange')$-HyperLogLog data structure, if $\symPrecision'\leq\symPrecision$ and $\symPrecision'+\symRegRange' \leq\symPrecision + \symRegRange$ is satisfied. This transformation is lossless in a sense that the resulting HyperLogLog sketch is the same as if all elements would have been recorded by a $(\symPrecision', \symRegRange')$-HyperLogLog sketch right from the beginning.

Note that a $(\symPrecision, 0)$-HyperLogLog sketch corresponds to a bit array as used by linear probabilistic counting \cite{Whang1990}. In this case each register value is represented by a single bit. Hence, linear probabilistic counting can be regarded as a special case of the HyperLogLog algorithm ($\symRegRange = 0$).

\begin{algorithm}
\caption{Insertion of a data element $\symDataItem$ into a HyperLogLog data structure that consists of $\symNumReg=2^\symPrecision$ registers $\vec{\symRegVal} = (\symRegVal_1,\ldots,\symRegVal_\symNumReg$) which are initialized to 0 and which can represent any integer in range $[0, \symRegRange+1]$.}
\label{alg:insert}
\begin{algorithmic}
\Procedure {InsertElement}{\symDataItem, $\vec{\symRegVal}$}
\State $\langle \symBitRepA_1, \ldots, \symBitRepA_\symPrecision,\symBitRepB_1,\ldots,\symBitRepB_\symRegRange\rangle_2 \gets$ $(\symPrecision + \symRegRange)$-bit hash value of $\symDataItem$
\State $\symIndexJ \gets 1+ \langle \symBitRepA_1, \ldots, \symBitRepA_\symPrecision\rangle_2$
\State $\symRegVal' = \min(\{\symS\mid \symS \in [1, \symRegRange]  \wedge  \symBitRepB_\symS = 1\}\cup {\{\symRegRange+1\}} )$
\State $\symRegVal_\symIndexJ \gets\max(\symRegVal_\symIndexJ, \symRegVal')$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Joint probability distribution of register values}

Under the assumption of an ideal hash function, the probability mass function for the register values $\vec{\symRegVal}=(\symRegVal_1,\ldots,\symRegVal_\symNumReg)$ of a HyperLogLog sketch with parameters $\symPrecision$ and $\symRegRange$ is given by
\begin{equation}
\label{equ:multinomialProbabilityMass}
\symProbabilityMass(\vec{\symRegVal}\vert\symCardinality)
=
\sum_{\symCardinality_1+\ldots+\symCardinality_\symNumReg = \symCardinality} \binom{\symCardinality}{\symCardinality_1,\ldots\symCardinality_\symNumReg}
\frac{1}{\symNumReg^\symCardinality}\prod_{\symIndexJ=1}^\symNumReg \symRegProbability_{\symCardinality_\symIndexJ\symRegVal_\symIndexJ},
\end{equation}
where $\symCardinality$ is the cardinality. The $\symCardinality$ distinct elements are distributed over all $\symNumReg$ registers according to a multinomial distribution with equal probabilities. $\symRegProbability_{\symNu\symKappa}$ is the probability that a register is equal to $\symKappa$ after inserting $\symNu$ distinct elements
\begin{equation}
\symRegProbability_{\symNu\symKappa} 
:=
\begin{cases}
1 & \symNu=0 \wedge \symKappa = 0\\
0 & \symNu=0 \wedge 1\leq\symKappa\leq\symRegRange+1\\
0 & \symNu\geq1 \wedge \symKappa = 0\\
\left(1-\frac{1}{2^\symKappa}\right)^\symNu - \left(1-\frac{1}{2^{\symKappa-1}}\right)^\symNu & \symNu \geq 1 \wedge 1\leq\symKappa\leq\symRegRange\\
1 - \left(1-\frac{1}{2^{\symRegRange}}\right)^\symNu & \symNu\geq 1 \wedge \symKappa = \symRegRange +1 \\
\end{cases}
\end{equation}

The order of register values $\symRegVal_1,\ldots,\symRegVal_\symNumReg$ is not important for the estimation of the cardinality. More formally, the multiset $\lbrace\symRegVal_1,\ldots,\symRegVal_\symNumReg\rbrace$ is a sufficient statistic for $\symCardinality$.
Since the values of the multiset are all in the range $[0, \symRegRange+1]$ the multiset can also be represented as $\lbrace\symRegVal_1,\ldots,\symRegVal_\symNumReg\rbrace = 0^{\symCount_0}1^{\symCount_1}\cdots\symRegRange^{\symCount_{\symRegRange}}(\symRegRange+1)^{\symCount_{\symRegRange+1}}$ where $\symCount_\symIndexJ$ is the multiplicity of value $\symIndexJ$. As a consequence, the multiplicity vector $\vec{\symCount} := (\symCount_0,\ldots,\symCount_{\symRegRange+1})$ is also a sufficient statistic for the cardinality. In addition, this vector contains all the information about the HyperLogLog sketch that is required for cardinality estimation. The two HyperLogLog parameters can be obtained by $\symPrecision = \log_2 \left\Vert\vec{\symCount}\right\Vert_1$ and $\symRegRange=\dim(\vec{\symCount})-2$, respectively.

\subsection{Poisson approximation}
\label{sec:poisson_approximation}
Unfortunately, the probability mass function \eqref{equ:multinomialProbabilityMass} is difficult to analyze, because the register values are statistically dependent. Therefore, as proposed in \cite{Flajolet2007} a Poisson model can be used, which assumes that the cardinality itself is distributed according to a Poisson distribution
\begin{equation}
\symCardinality \sim \text{Poisson}(\symPoissonRate).
\end{equation}
Under the Poisson model the distribution of the register values is
\begin{align}
\symProbabilityMass(\vec{\symRegVal}\vert\symPoissonRate) 
&= 
\sum_{\symCardinality=0}^\infty \symProbabilityMass(\vec{\symRegVal}\vert\symCardinality) e^{-\symPoissonRate}\frac{\symPoissonRate^\symCardinality}{\symCardinality!}
\label{equ:poissonization}
\\
&= 
\sum_{\symCardinality_1=0}^\infty
\cdots
\sum_{\symCardinality_\symNumReg=0}^\infty
\prod_{\symIndexJ=1}^\symNumReg
\symRegProbability_
{\symCardinality_\symIndexJ\symRegVal_\symIndexJ}e^{-\frac{\symPoissonRate}{\symNumReg}}\frac{\symPoissonRate^{\symCardinality_\symIndexJ}}{\symCardinality_\symIndexJ!\symNumReg^{\symCardinality_\symIndexJ}}
\nonumber\\
&= 
\prod_{\symIndexJ=1}^\symNumReg \sum_{\symCardinality=0}^\infty\symRegProbability_
{\symCardinality\symRegVal_\symIndexJ}e^{-\frac{\symPoissonRate}{\symNumReg}}\frac{\symPoissonRate^\symCardinality}{\symCardinality!\symNumReg^\symCardinality}
\nonumber\\
&= 
\prod_{\symRegVal=0}^{\symRegRange+1} \left[
\sum_{\symCardinality=0}^\infty
\symRegProbability_
{\symCardinality\symRegVal}e^{-\frac{\symPoissonRate}{\symNumReg}}\frac{\symPoissonRate^\symCardinality}{\symCardinality!\symNumReg^\symCardinality}
\right]^{\symCount_\symRegVal}
\nonumber\\
&=
e^{-\symCount_0\frac{\symPoissonRate}{\symNumReg}}
\cdot
\left(\prod_{\symRegVal=1}^{\symRegRange}\left(e^{-\frac{\symPoissonRate}{\symNumReg 2^\symRegVal}}\left(1-e^{-\frac{\symPoissonRate}{\symNumReg 2^\symRegVal}}\right)\right)^{\symCount_\symRegVal}\right)
\cdot
\left(1-e^{-\frac{\symPoissonRate}{\symNumReg 2^\symRegRange}}\right)^{\symCount_{\symRegRange+1}}.
\end{align}
The final factorization shows that all register values are independent and identically distributed under the Poisson model. The probability that a register has a value less than or equal to $\symRegVal$ for a given rate $\symPoissonRate$ is given by
\begin{equation}
\label{equ:register_value_distribution}
\symProbability(\symRegValVariate \leq \symRegVal\vert\symPoissonRate)
=
\begin{cases}
0 & \symRegVal < 0 \\
e^{-\frac{\symPoissonRate}{\symNumReg 2^\symRegVal}} & 0\leq \symRegVal \leq \symRegRange \\
1 & \symRegVal > \symRegRange
\end{cases}
\end{equation}

\subsection{Depoissonization}
Due to the simpler probability mass function, it is easier to find an estimator $\symPoissonRateEstimate = \symPoissonRateEstimate(\vec{\symRegValVariate})$ for the Poisson rate $\symPoissonRate$ rather than for the cardinality $\symCardinality$ in the fixed-size model \eqref{equ:multinomialProbabilityMass}. Here $\vec{\symRegValVariate}$ denotes the vector of all observed register values. $\vec{\symRegValVariate}$ is distributed according to \eqref{equ:multinomialProbabilityMass}. Depoissonization \cite{Jacquet1998} finally allows to translate the estimates back to the fixed-size model. Assume we have found an unbiased estimator for the Poisson rate
\begin{equation}
\symExpectation(\symPoissonRateEstimate\vert\symPoissonRate) = \symPoissonRate
\quad
\text{for all $\symPoissonRate\geq 0$}.
\end{equation}
We know from \eqref{equ:poissonization} 
\begin{equation}
\symExpectation(\symPoissonRateEstimate\vert\symPoissonRate) = 
\sum_{\symCardinality=0}^\infty \symExpectation(\symPoissonRateEstimate\vert\symCardinality) e^{-\symPoissonRate}\frac{\symPoissonRate^\symCardinality}{\symCardinality!}
\end{equation}
and therefore
\begin{equation}
\sum_{\symCardinality=0}^\infty \symExpectation(\symPoissonRateEstimate\vert\symCardinality) e^{-\symPoissonRate}\frac{\symPoissonRate^\symCardinality}{\symCardinality!}
=
\symPoissonRate
\end{equation}
holds for all $\symPoissonRate\geq0$. The inverse Poisson transform gives
\begin{equation}
\symExpectation(\symPoissonRateEstimate\vert\symCardinality) = \symCardinality.
\end{equation}
Therefore, the unbiased estimator $\symPoissonRateEstimate$ conditioned on $\symCardinality$ is also an unbiased estimator for $\symCardinality$. Hence, it makes sense to use $\symPoissonRateEstimate$ directly as estimate for the cardinality $\symCardinalityEstimate := \symPoissonRateEstimate$. As simulation results will show later, the Poisson approximation works well over the entire cardinality range, even for estimators that are not exactly unbiased.

\section{Original cardinality estimation method}
\label{sec:cardinality_estimation}
The original cardinality estimate \cite{Flajolet2007} is based on the idea that approximately $\symNumReg  2^{\symRegVal_\symIndexJ}$ distinct element insertions are needed until the value of register $\symIndexJ$ reaches $\symRegVal_\symIndexJ$. Given that, a cardinality estimate can be obtained by calculating the average over the values $\lbrace \symNumReg 2^{\symRegVal_1},\ldots,\symNumReg2^{\symRegVal_\symNumReg}\rbrace$. 

In the history of the HyperLogLog algorithm different averaging techniques have been proposed. First, there was the LogLog algorithm using the geometric mean and the SuperLogLog algorithm that enhanced the estimate by truncating the largest register values before applying the geometric mean \cite{Durand2003}. Finally, the harmonic mean was found to give even better estimates as it is inherently less sensitive to outliers. The result is the so-called raw HyperLogLog estimate and given by
\begin{equation}
\label{equ:intermediate_estimate}
\symCardinalityOriginalEstimate
= 
\frac{\symAlpha_\symNumReg \symNumReg^2}{\sum_{\symIndexJ=1}^{\symNumReg}2^{-\symRegVal_\symIndexJ}}
= 
\frac{\symAlpha_\symNumReg \symNumReg^2}{\sum_{\symRegVal=0}^{\symRegRange+1}\symCount_\symRegVal 2^{-\symRegVal}}
\end{equation}
where $\symAlpha_\symNumReg$  is a correction factor that is fixed for a given number of registers $\symNumReg$ and which was derived to be \cite{Flajolet2007}
\begin{equation}
\symAlpha_\symNumReg := \left(
\symNumReg
\int_0^\infty
\left(
\log_2\left(
\frac{2+u}{1+u}
\right)
\right)^\symNumReg
du
\right)^{-1}.
\end{equation}
Numerical approximations of $\symAlpha_\symNumReg$ for various values of $\symNumReg$ have been listed in \cite{Flajolet2007}. These approximations are used in many HyperLogLog implementations. However, since the published constants have been rounded to 4 significant digits, these approximations even introduce some bias for very high precisions $\symPrecision\geq 20$. For HyperLogLog sketches that are used in practice with 256 or more registers ($\symPrecision\geq 8$), it is completely sufficient to use 
\begin{equation}
\label{equ:alpha_inf}
\symAlpha_\infty := \lim_{\symNumReg\rightarrow\infty} \symAlpha_\symNumReg = \frac{1}{2\log 2} \approx 0.7213475,
\end{equation}
as approximation for $\symAlpha_\symNumReg$ in \eqref{equ:intermediate_estimate}, because the additional bias is negligible if compared to the estimation error.

\cref{fig:raw_estimate} shows the distribution of the relative error for the raw estimate as function of the cardinality. The chart is based on 10\,000 randomly generated HyperLogLog sketches. Obviously, the raw estimator is biased for small and large cardinalities and fails to return accurate estimates. Therefore, to cover the entire range of cardinalities, corrections for small and large cardinalities have been proposed, respectively.

As mentioned in \cref{sec:data_element_insertion}, a HyperLogLog sketch with parameters $(\symPrecision, \symRegRange)$ can be turned into a $(\symPrecision, 0)$-HyperLogLog sketch. Since $\symRegRange=0$ corresponds to linear probabilistic counting and the transformed HyperLogLog sketch corresponds to a bitset with $\symCount_0$ zeros, we can apply the corresponding cardinality estimator \cite{Whang1990}
\begin{equation}
\label{equ:small_range_estimate}
\symCardinalityEstimate_\text{small} = \symNumReg \log\left(
\frac{\symNumReg}{\symCount_0}
\right).
\end{equation}
The corresponding relative estimation error as depicted in \cref{fig:small_range_estimate} shows that this estimator is convenient for small cardinalities. It was proposed to use this small-range estimator as long as $\symCardinalityOriginalEstimate \leq \frac{5}{2}\symNumReg$ where the factor $\frac{5}{2}$ was empirically determined \cite{Flajolet2007}. 

For large cardinalities in the order of $2^{\symPrecision+\symRegRange}$, for which a lot of registers are already in a saturated state meaning that they have reached the maximum possible value $\symRegRange + 1$, the raw estimator underestimates the cardinalities. For the 32-bit hash value case $(\symPrecision+\symRegRange=32)$ which was considered in \cite{Flajolet2007}, following correction formula was proposed to take these saturated registers into account
\begin{equation}
\label{equ:large_range_estimate}
\symCardinalityEstimate_\text{large}
=
-2^{32}\log\left(1-\frac{\symCardinalityOriginalEstimate}{2^{32}}\right).
\end{equation}

The original estimation algorithm as presented in \cite{Flajolet2007} including small and large range corrections is summarized by \cref{alg:estimate_original}. 
\begin{algorithm}
\caption{Original procedure for estimating the cardinality from a  HyperLogLog data structure using 32-bit hash values ($\symPrecision+\symRegRange = 32$) for insertion of data items \cite{Flajolet2007}.}
\label{alg:estimate_original}
\begin{algorithmic}
\Function {EstimateCardinality}{$\vec{\symRegVal}$}
\State $\symNumReg \gets \dim \vec{\symRegVal}$
\State $\symCardinalityOriginalEstimate = \symAlpha_\symNumReg \symNumReg^2\left(\sum_{\symIndexJ=1}^\symNumReg 2^{-\symRegVal_\symIndexJ}\right)^{-1}$
\Comment raw estimate \eqref{equ:intermediate_estimate}
\If{$\symCardinalityOriginalEstimate\leq \frac{5}{2}\symNumReg$}
\State $\symCount_0 = \left|\{\symIndexJ |\symRegVal_\symIndexJ=0\}\right|$
\If{$\symCount_0\neq0$}
\State \Return $\symNumReg \log(\symNumReg / \symCount_0)$ \Comment small range correction \eqref{equ:small_range_estimate}
\Else
\State \Return $\symCardinalityOriginalEstimate$
\EndIf
\ElsIf{$\symCardinalityOriginalEstimate\leq \frac{1}{30}2^{32}$}
\State \Return $\symCardinalityOriginalEstimate$
\Else
\State\Return $-2^{32}\log(1-\symCardinalityOriginalEstimate/2^{32})$\Comment large range correction \eqref{equ:large_range_estimate}
\EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}
The relative estimation error for the original method is shown in \cref{fig:original_estimate}. Unfortunatley, as can be clearly seen, the ranges where the estimation error is small for $\symCardinalityOriginalEstimate$ and $\symCardinalityEstimate_\text{small}$ do not overlap. Therefore, the estimation error is much larger near the transition region. To reduce the estimation error for cardinalities close to this region, it was proposed to correct $\symCardinalityOriginalEstimate$ for bias. The empirically determined bias correction data can be either stored as set of interpolation points \cite{Heule2013}, as lookup table \cite{Rhodes2015}, or as best-fitting polynomial \cite{Sanfilippo2014}. 

\begin{figure}
\centering
\includesvg[width=1\textwidth]{raw_estimate}
\caption{The distribution of the relative estimation error over the cardinality as for the raw estimator \cite{Flajolet2007}. 10\,000 randomly generated HyperLogLog data structures with parameters $\symPrecision = 12$ and $\symRegRange=20$ have been evaluated.}
\label{fig:raw_estimate}
\end{figure}

\begin{figure}
\centering
\includesvg[width=1\textwidth]{small_range_estimate}
\caption{The distribution of the relative estimation error for the linear probabilistic counting estimator which can be used for small cardinalities.}
\label{fig:small_range_estimate}
\end{figure}

\begin{figure}
\centering
\includesvg[width=1\textwidth]{original_estimate}
\caption{The distribution of the relative estimation error over the cardinality as obtained by the original estimation method \cite{Flajolet2007}. 10\,000 randomly generated HyperLogLog data structures with parameters $\symPrecision = 12$ and $\symRegRange=20$ have been evaluated.}
\label{fig:original_estimate}
\end{figure}

The large range correction is not satisfying either as it does not reduce the estimation error. Quite the contrary, it even increases the estimation error. However, instead of underestimating the cardinalities, they are now overestimated. A simple approach to avoid the large range correction at all is the use of larger hash values $(\symPrecision+\symRegRange>32)$ which shift the biased region of $\symCardinalityOriginalEstimate$ to higher cardinalities. However, in case $\symRegRange \geq 30$ 6-bit registers as used in \cite{Heule2013} are required to allow representing all values in the range $[0, \symRegRange+1]$. If 64-bit hash values are used as proposed in \cite{Heule2013} $(\symPrecision+\symRegRange=64)$, a correction for large cardinalities can be circumvented. Cardinalities in the order of $2^{64}$ for which saturated registers become a problem never occur in practice.

%\begin{algorithm}
%\caption{Calculate the sufficient statistic $\vec{\symCount}=(\symCount_0, \ldots,\symCount_{\symRegRange+1})$ for given register values $\vec{\symRegVal} = (\symRegVal_1,\ldots,\symRegVal_\symNumReg)$.}
%\begin{algorithmic}
%\Function {CountRegisterValues}{$\vec{\symRegVal}$}
%\State $\vec{\symCount}\gets\vec{0}$
%\ForAll{$\symRegVal'\in\lbrace\symRegVal_1,\ldots,\symRegVal_\symNumReg\rbrace$}
%\State $\symCount_{\symRegVal'} \gets \symCount_{\symRegVal'} + 1$
%\EndFor
%\State\Return $\vec{\symCount}$
%\EndFunction
%\end{algorithmic}
%\end{algorithm}
%

\subsection{Derivation of the raw estimator}
In order to better understand why the raw estimator fails for small and large cardinalities, we start with a brief derivation that does not require complex analysis. 

Consider following integer distribution
\begin{equation}
\label{equ:assumed_register_val_distribution}
\symProbability(\symRegValVariate \leq \symRegVal\vert\symPoissonRate) = e^{-\frac{\symPoissonRate}{\symNumReg 2^{ \symRegVal}}}.
\end{equation}
This distribution has infinite support and differs from the register value distribution under the Poisson model \eqref{equ:register_value_distribution}, whose support is limited to the range $[0, \symRegRange+1]$. The expectation of $2^{-\symRegVal}$ is given by
\begin{multline}
\label{equ:expectation_power_two}
\symExpectation(2^{-\symRegVal})
=
\\
\sum_{\symRegVal = -\infty}^\infty
2^{-\symRegVal}
e^{-\frac{\symPoissonRate}{\symNumReg} 2^{-\symRegVal}}
\left(1-e^{-\frac{\symPoissonRate}{\symNumReg} 2^{-\symRegVal}}\right)
=
\frac{1}{2}
\sum_{\symRegVal = -\infty}^\infty
2^{\symRegVal}
e^{-\frac{\symPoissonRate}{\symNumReg} 2^{\symRegVal}}
=
\frac{\symAlpha_\infty\,\symNumReg\,\symPowerSeriesFunc\!\left(\log_2\left( \frac{\symPoissonRate}{\symNumReg}\right)\right)}{\symPoissonRate},
\end{multline}
where the function 
\begin{equation}
\label{equ:power_series_function}
\symPowerSeriesFunc(\symX):= \log(2) \sum_{\symRegVal = -\infty}^\infty
2^{\symRegVal+\symX}
e^{-2^{\symRegVal+\symX}}
\end{equation}
 is a smooth periodic function with period 1. Numerical evaluations indicate that this function can be bounded by $1 - \symEpsPowerSeriesFunc 
\leq \symPowerSeriesFunc(\symX) \leq 1 + \symEpsPowerSeriesFunc$ with $\symEpsPowerSeriesFunc:=9.885\cdot 10^{-6}$ (see \cref{fig:power_series_func}).

\begin{figure}
\centering
\includesvg[width=0.6\textwidth]{power-series-function-minus-1}
\caption{The deviation of $\symPowerSeriesFunc(\symX)$ from 1.}
\label{fig:power_series_func}
\end{figure}


Let $\symRegVal_1,\ldots,\symRegVal_\symNumReg$ be a sample taken from \eqref{equ:assumed_register_val_distribution}. For large sample sizes $\symNumReg\rightarrow \infty$ we have asymptotically
\begin{equation}
\symExpectation\left(
\frac{1}{2^{-\symRegVal_1}+\ldots+2^{-\symRegVal_\symNumReg}}
\right)
\underset{\symNumReg\rightarrow \infty}{=}
\frac{1}{\symExpectation
\left(2^{-\symRegVal_1}+\ldots+2^{-\symRegVal_\symNumReg}\right)}
=
\frac{1}{\symNumReg \symExpectation\left(2^{-\symRegVal}\right)}.
\end{equation}
Together with \eqref{equ:expectation_power_two} we obtain
\begin{equation}
\symPoissonRate
=
\symExpectation\left(
\frac{\symAlpha_\infty\,\symNumReg^2\,\symPowerSeriesFunc\!\left(\log_2\left( \symPoissonRate/\symNumReg\right)\right)}{2^{-\symRegVal_1}+\ldots+2^{-\symRegVal_\symNumReg}}
\right)
\quad
\text{for $\symNumReg\rightarrow \infty$}.
\end{equation}
Therefore, 
\begin{equation}
\label{equ:rawestimator_2}
\symPoissonRateEstimate 
= 
\frac{\symAlpha_\infty\,\symNumReg^2}{2^{-\symRegVal_1}+\ldots+2^{-\symRegVal_\symNumReg}}
\end{equation}
is an asymptotically almost unbiased estimator for the Poisson parameter. Its asymptotic relative bias is bounded by $\symEpsPowerSeriesFunc$. This estimator corresponds to the raw estimator \eqref{equ:intermediate_estimate}, if the Poisson parameter estimate is used as cardinality estimate (see \cref{sec:poisson_approximation}).

The estimator \eqref{equ:rawestimator_2} can also be written as
\begin{equation}
\label{equ:raw_estimate_with_multiplicities}
\symPoissonRateEstimate 
= 
\frac{\symAlpha_\infty\,\symNumReg^2}{\sum_{\symRegVal=-\infty}^\infty \symCount'_\symRegVal 2^{-\symRegVal}},
\end{equation}
if $\symCount'_\symRegVal$ is the multiplicity of value $\symRegVal$ in the sample $\left\lbrace \symRegVal_1,\ldots,\symRegVal_\symNumReg\right\rbrace$. 
By definition, we have $\sum_{\symRegVal=-\infty}^\infty \symCount'_\symRegVal = \symNumReg$. 

\subsection{Limitations of the raw estimator}
As we have already seen in \cref{fig:raw_estimate}, the raw estimator does not work very well for small or large cardinalities. The reason for this is that the distribution of register values \eqref{equ:register_value_distribution} is different from \eqref{equ:assumed_register_val_distribution} for which the raw estimator was derived. Since a random variable $\symRegValVariate'$ that obeys \eqref{equ:assumed_register_val_distribution} can be transformed into random variable $\symRegValVariate$ that follows \eqref{equ:register_value_distribution} using the transformation $\symRegValVariate = \min\left(\max\left(\symRegValVariate', 0\right), \symRegRange+1\right)$, the register values of a HyperLogLog sketch can be seen as the result after applying this transformation to a sample that is distributed according to \eqref{equ:assumed_register_val_distribution}. The corresponding multiplicities have  following relationships
\begin{equation}
\label{equ:multiplicity_transformation}
\begin{aligned}
\symCount_0 &= \textstyle\sum_{\symRegVal = -\infty}^{0} \symCount'_\symRegVal, \\
\symCount_\symRegVal &=  \symCount'_\symRegVal, \quad 1\leq\symRegVal\leq\symRegRange,\\
\symCount_{\symRegRange+1} &= \textstyle\sum_{\symRegVal = \symRegRange + 1}^{\infty} \symCount'_\symRegVal.
\end{aligned}
\end{equation}
Obviously, as long as $\symCount_0\approx\symCount'_0$ and  $\symCount'_{\symRegRange+1}\approx\symCount_{\symRegRange+1}$ the set of register values is similar to the originating sample. In case $\symCount_0=0$ and $\symCount_{\symRegRange+1}=0$, which implies $\symCount_\symRegVal=0$ for $\symRegVal\leq0$ and $\symRegVal\geq\symRegRange+1$, we can even be sure that the register values are identical to the originating sample. However, for small and large cardinalities $\symCount_0$ and $\symCount_{\symRegRange+1}$ approach $\symNumReg$, respectively, and the raw estimator needs to be corrected.

\subsection{Corrections to the raw estimator}
Given a HyperLogLog sketch with multiplicity vector $\vec{\symCount}$, we try to find estimates $\hat{\symCount}'_\symRegVal$ for $\symCount'_\symRegVal$ for all $\symRegVal\in\mathbb{Z}$ and use them instead in the estimation formula \eqref{equ:raw_estimate_with_multiplicities}. For $\symRegVal\in[1,\symRegRange]$ where $\symCount_\symRegVal = \symCount'_\symRegVal$ we have the trivial estimators 
\begin{equation}
\hat{\symCount}'_\symRegVal := \symCount_\symRegVal,\quad 1\leq\symRegVal\leq\symRegRange.
\end{equation}
To get estimators for all other $\symRegVal$, we consider their expectations
\begin{equation}
\symExpectation(\symCount'_\symRegVal)
=
\symNumReg e^{-\frac{\symPoissonRate}{\symNumReg 2^{\symRegVal}}}\left(1-e^{-\frac{\symPoissonRate}{\symNumReg 2^{\symRegVal}}}\right).
\end{equation}
From \eqref{equ:register_value_distribution} we know that $\symExpectation\left(\frac{\symCount_0}{\symNumReg}\right)=
e^{-\frac{\symPoissonRate}{\symNumReg}}$ and $\symExpectation\left(1-\frac{\symCount_{\symRegRange+1}}{\symNumReg}\right)=
e^{-\frac{\symPoissonRate}{\symNumReg 2^\symRegRange}}$, and therefore, we can also write
\begin{equation}
\symExpectation(\symCount'_\symRegVal)
=
\symNumReg
\symExpectation\left(\frac{\symCount_0}{\symNumReg}\right)^{2^{-\symRegVal}}
\left(1-\symExpectation\left(\frac{\symCount_0}{\symNumReg}\right)^{2^{-\symRegVal}}\right)
\end{equation}
and
\begin{equation}
\symExpectation(\symCount'_\symRegVal)
=
\symNumReg
\symExpectation\left(1-\frac{\symCount_{\symRegRange+1}}{\symNumReg}\right)^{2^{\symRegRange-\symRegVal}}
\left(1-\symExpectation\left(1-\frac{\symCount_{\symRegRange+1}}{\symNumReg}\right)^{2^{\symRegRange-\symRegVal}}\right),
\end{equation}
which motivates us to use
\begin{equation}
\hat{\symCount}'_\symRegVal
:=
\symNumReg\cdot
\left(\frac{\symCount_0}{\symNumReg}\right)^{2^{-\symRegVal}}\cdot
\left(1-\left(\frac{\symCount_0}{\symNumReg}\right)^{2^{-\symRegVal}}\right)
\end{equation}
as estimator for $\symRegVal \leq 0$ and
\begin{equation}
\hat{\symCount}'_\symRegVal
:=
\symNumReg\cdot
\left(1-\frac{\symCount_{\symRegRange+1}}{\symNumReg}\right)^{2^{\symRegRange-\symRegVal}}
\cdot
\left(1-\left(1-\frac{\symCount_{\symRegRange+1}}{\symNumReg}\right)^{2^{\symRegRange-\symRegVal}}\right)
\end{equation}
as estimator for $\symRegVal \geq \symRegRange+1$, respectively.

Inserting all these estimators into \eqref{equ:raw_estimate_with_multiplicities} finally gives
\begin{equation}
\label{equ:correctedestimator}
\symPoissonRateEstimate 
= 
\frac{\symAlpha_\infty\symNumReg^2}{\sum_{\symRegVal=-\infty}^\infty \hat{\symCount}'_\symRegVal 2^{-\symRegVal}}
=
\frac{\symAlpha_\infty\symNumReg^2}
{
\left(
\symNumReg\,\symSmallCorrectionFunc(\symCount_0/\symNumReg) + \sum_{\symRegVal=1}^\symRegRange \symCount_\symRegVal 2^{-\symRegVal} + \symNumReg\, \symLargeCorrectionFunc(1-\symCount_{\symRegRange+1}/\symNumReg) 2^{-(\symRegRange+1)}
\right)}
\end{equation}
which we call the corrected raw estimator. Here $\symNumReg\,\symSmallCorrectionFunc(\symCount_0/\symNumReg)$ and $\symNumReg\,\symLargeCorrectionFunc(1-\symCount_{\symRegRange+1}/\symNumReg)$ are replacements for  $\symCount_0$ and $\symCount_{\symRegRange+1}$ in the raw estimator \eqref{equ:intermediate_estimate}, respectively. The functions $\symSmallCorrectionFunc$ and $\symLargeCorrectionFunc$ are defined as
\begin{equation}
\symSmallCorrectionFunc(\symX) := 
\symX
+
\sum_{\symRegVal=1}^\infty
\symX^{2^\symRegVal} 2^{\symRegVal-1}
\end{equation}
and
\begin{equation}
\symLargeCorrectionFunc(\symX)
:=
\sum_{\symRegVal=1}^\infty
\symX^{2^{-\symRegVal}}
\cdot
\left(1-\symX^{2^{-\symRegVal}}\right)
\cdot
2^{-(\symRegVal-1)}.
\end{equation}

Note that, $2\symSmallCorrectionFunc(\symX) + \symLargeCorrectionFunc(\symX) = -\symPowerSeriesFunc(\log_2(-\log(\symX)))/\left(\log(2)\log(\symX)\right)$. Therefore, we get for the special case of linear probabilistic counting with $\symRegRange=0$
\begin{equation}
\symPoissonRateEstimate 
= 
\frac{\symNumReg}{\log(2)\left(
2\symSmallCorrectionFunc(\symCount_0/\symNumReg)
+
\symLargeCorrectionFunc(\symCount_0/\symNumReg)
\right)}
=
\frac{\symNumReg\log\left(\frac{\symNumReg}{\symCount_0}\right)}{\symPowerSeriesFunc\left(\log_2\left(\log\left(\frac{\symNumReg}{\symCount_0}\right)\right)\right)}
\approx
\symNumReg\log\left(\frac{\symNumReg}{\symCount_0}\right).
\end{equation}
almost the same estimator as given in \eqref{equ:small_range_estimate}. Here we used the fact that $\symPowerSeriesFunc$ can be well approximated by 1.
\subsection{Corrected raw estimation algorithm}
The corrected raw estimator \eqref{equ:correctedestimator} leads to a new cardinality estimation algorithm for HyperLogLog sketches. \cref{alg:corrected_raw_estimation} demonstrates the numerical evaluation of the estimator. The values of functions $\symSmallCorrectionFunc$ and $\symLargeCorrectionFunc$ can be either calculated on-demand or pre-calculated. The possible value range for $\symCount_0$ and $\symCount_{\symRegRange+1}$ is $[0, \symNumReg]$. Therefore, if performance matters, it is possible to precalculate the function values for all possible arguments and keep them in lookup tables of size $\symNumReg+1$. 

\begin{algorithm}
\caption{Cardinality estimation algorithm based on the corrected raw estimate.}
\label{alg:corrected_raw_estimation}
\begin{algorithmic}
\Function {EstimateCardinality}{$\vec{\symCount}$}
\State $\symNumReg \gets \left\Vert\vec{\symCount}\right\Vert_1$
\State $\symZ\gets 0.5\cdot \symNumReg\cdot\symLargeCorrectionFunc(1 - \symCount_{\symRegRange+1}/\symNumReg)$
\Comment{\parbox[t]{.5\linewidth}{alternatively, take $0.5\cdot \symNumReg\cdot\symLargeCorrectionFunc(1 - \symCount_{\symRegRange+1}/\symNumReg)$ from precalculated lookup table}}
\For{$\symRegVal\gets \symRegRange, 1$}
\State $\symZ\gets0.5\cdot\left(\symZ + \symCount_\symRegVal\right)$
\EndFor
\State $\symZ\gets\symZ+\symNumReg\cdot\symSmallCorrectionFunc(\symCount_0/\symNumReg)$
\Comment{\parbox[t]{.5\linewidth}{alternatively, take $\symNumReg\cdot\symSmallCorrectionFunc(\symCount_0/\symNumReg)$ from precalculated lookup table}}
\State \Return$\symNumReg^2 / \left(2\log(2)\symZ\right)$
\EndFunction
\\
\Function {$\symSmallCorrectionFunc$}{$\symX$}
\Comment $\symX\in[0,1]$
\If{$\symX=1$}
\State\Return$\infty$
\EndIf
\State $\symY\gets1$
\State $\symZ\gets\symX$
\Repeat
\State $\symX\gets\symX\cdot\symX$
\State $\symZ'\gets\symZ$
\State $\symZ\gets\symZ + \symX\cdot\symY$
\State $\symY\gets2\cdot\symY$
\Until{$\symZ=\symZ'$}
\State\Return$\symZ$
\EndFunction
\\
\Function {$\symLargeCorrectionFunc$}{$\symX$}
\Comment $\symX\in[0,1]$
\State $\symY\gets1$
\State $\symZ\gets0$
\Repeat
\State $\symX\gets\sqrt{\symX}$
\State $\symZ'\gets\symZ$
\State $\symZ\gets\symZ + \left(1-\symX\right)\cdot\symX\cdot\symY$
\State $\symY\gets0.5\cdot\symY$
\Until{$\symZ=\symZ'$}
\State\Return$\symZ$
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Estimation error}



see \cref{fig:raw_corrected_estimation_error_8_24}, \cref{fig:raw_corrected_estimation_error_12_20},
\cref{fig:raw_corrected_estimation_error_16_16},
\cref{fig:raw_corrected_estimation_error_22_10},

\begin{figure}
\centering
\includesvg[width=1\textwidth]{raw_corrected_estimate_8_24}
\caption{Relative estimation error as a function of the true cardinality for a HyperLogLog sketch with parameters $\symPrecision = 8$ and $\symRegRange=24$.}
\label{fig:raw_corrected_estimation_error_8_24}
\end{figure}

\begin{figure}
\centering
\includesvg[width=1\textwidth]{raw_corrected_estimate_12_20}
\caption{Relative estimation error as a function of the true cardinality for a HyperLogLog sketch with parameters $\symPrecision = 12$ and $\symRegRange=20$.}
\label{fig:raw_corrected_estimation_error_12_20}
\end{figure}

\begin{figure}
\centering
\includesvg[width=1\textwidth]{raw_corrected_estimate_16_16}
\caption{Relative estimation error as a function of the true cardinality for a HyperLogLog sketch with parameters $\symPrecision = 16$ and $\symRegRange=16$.}
\label{fig:raw_corrected_estimation_error_16_16}
\end{figure}

\begin{figure}
\centering
\includesvg[width=1\textwidth]{raw_corrected_estimate_22_10}
\caption{Relative estimation error as a function of the true cardinality for a HyperLogLog sketch with parameters $\symPrecision = 22$ and $\symRegRange=10$.}
\label{fig:raw_corrected_estimation_error_22_10}
\end{figure}


\subsection{Performance}
see \cref{fig:corrected_raw_avg_exec_time}

\begin{figure}
\centering
\includesvg[width=1\textwidth]{corrected_raw_avg_exec_time}
\caption{Average computation time as a function of the true cardinality with an Intel Core i5-2500K clocking at 3.3GHz when estimating the cardinality from HyperLogLog sketches with parameters $\symPrecision=12$, $\symRegRange=20$ and $\symPrecision=12$, $\symRegRange=52$, respectively. Both cases, $\symSmallCorrectionFunc$ and $\symLargeCorrectionFunc$ precalculated and calculated on-demand have been considered.}
\label{fig:corrected_raw_avg_exec_time}
\end{figure}

\section{Maximum likelihood estimation}

The maximum likelihood method was already applied to HyperLogLog sketches in \cite{Clifford2012}. However, there, a different element insertion algorithm was assumed that works with time complexity $\symBigO(\symNumReg)$, because each register calculates its own hash value from the inserted element and updates its current value accordingly. In comparison, \cref{alg:insert} uses only a single hash value that defines which register needs to be updated. As a consequence, the register values are statistically dependent, and the Poisson approximation is needed to make the register values statistically independent, which allows the factorization of the joint probability distribution of all register values.

In the following we derive a new robust and efficient cardinality estimation algorithm that is based on the maximum likelihood method. Furthermore, we will demonstrate that consequent application of the maximum likelihood method reveals that the cardinality estimate needs to be roughly proportional to the harmonic mean for intermediate cardinality values. The history of the HyperLogLog algorithm shows that the raw estimate \eqref{alg:estimate_original} was first found after several attempts using the geometric mean \cite{Flajolet2007, Durand2003}.

\subsection{Log-likelihood function}

Under the Poisson model the log-likelihood and its derivative are given by
\begin{equation}
\label{equ:log_likelihood_single}
\log \mathcal{\symLikelihood}(\symPoissonRate\vert\vec{\symRegVal}) = 
-\frac{\symPoissonRate}{\symNumReg}\sum_{\symRegVal=0}^{\symRegRange}\frac{\symCount_\symRegVal}{2^\symRegVal}+ 
\sum_{\symRegVal=1}^{\symRegRange}\symCount_\symRegVal \log\left(1-e^{-\frac{\symPoissonRate}{\symNumReg 2^\symRegVal}}\right)
+
\symCount_{\symRegRange+1} \log\left(1-e^{-\frac{\symPoissonRate}{\symNumReg 2^{\symRegRange}}}\right)
\end{equation}
and
\begin{equation}
\frac{d}{d\symPoissonRate}\log \mathcal{\symLikelihood}(\symPoissonRate\vert\vec{\symRegVal}) 
=
-\frac{1}{\symPoissonRate}\left(
\frac{\symPoissonRate}{\symNumReg}\sum_{\symRegVal=0}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}+
\sum_{\symRegVal=1}^\symRegRange \symCount_\symRegVal\frac{\frac{\symPoissonRate}{\symNumReg 2^\symRegVal}}{1-e^{\frac{\symPoissonRate}{\symNumReg 2^\symRegVal}}}
+\symCount_{\symRegRange+1}\frac{\frac{\symPoissonRate}{\symNumReg 2^\symRegRange}}{1-e^{\frac{\symPoissonRate}{\symNumReg 2^\symRegRange}}}
\right).
\end{equation}
As a consequence, the maximum-likelihood estimate for the Poisson parameter is given by 
\begin{equation}
\symPoissonRateEstimate = \symNumReg\symXEstimate,
\end{equation}
if $\symXEstimate$ is the root of the function
\begin{equation}
\label{equ:funcdef}
\symFunc(\symX)
:=
\symX\sum_{\symRegVal=0}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}+
\sum_{\symRegVal=1}^\symRegRange \symCount_\symRegVal\frac{\frac{\symX}{2^\symRegVal}}{1-e^{\frac{\symX}{2^\symRegVal}}}
+\symCount_{\symRegRange+1}\frac{\frac{\symX}{2^\symRegRange}}{1-e^{\frac{\symX}{2^\symRegRange}}}.
\end{equation}
This function can also be written as
\begin{equation}
\label{equ:func}
\symFunc(\symX)
:=
\symX\sum_{\symRegVal=0}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}+
\sum_{\symRegVal=1}^\symRegRange \symCount_\symRegVal\symHelper\left(\frac{\symX}{2^\symRegVal}\right)
+
\symCount_{\symRegRange+1}\symHelper\left(\frac{\symX}{2^\symRegRange}\right)
-
\left(\symNumReg-\symCount_0\right),
\end{equation}
where the function $\symHelper(\symX)$ is defined as
\begin{equation}
\label{equ:helper}
\symHelper(\symX):=1-\frac{\symX}{e^{\symX}-1}.
\end{equation}
$\symHelper(\symX)$ is strictly increasing and concave as can be seen in \cref{fig:helper_function}. For non-negative values $\symX$ the function ranges from $\symHelper(0)=0$ to $\symHelper(\symX\rightarrow \infty)=1$.
\begin{figure}
\centering
\includesvg[width=0.45\textwidth]{helper}
\caption{The function $\symHelper(\symX)$.}
\label{fig:helper_function}
\end{figure}
Since the function $\symFunc(x)$ is also strictly increasing, it is obvious that there exists a unique root $\symXEstimate$ for which $\symFunc(\symXEstimate)=0$. The function is non-positive at 0 since $\symFunc(0)=\symCount_0-\symNumReg\leq 0$ and, in case $\symCount_{\symRegRange+1}<\symNumReg$ which implies $\sum_{\symRegVal=0}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}>0$, the function is at least linearly increasing. $\symCount_{\symRegRange+1}=\symNumReg$ corresponds to the case with all registers equal to the maximum value $(\symRegRange+1)$, for which the maximum likelihood estimate would be infinity.

It is easy to see that the estimate $\symPoissonRateEstimate$ remains equal or becomes larger, when inserting an element into the HyperLogLog sketch following \cref{alg:insert}. An update potentially changes the multiplicity vector $(\symCount_0,\ldots,\symCount_{\symRegRange+1})$ to $(\symCount_0,\ldots,\symCount_\symIndexI-1,\ldots,\symCount_\symIndexJ+1,\ldots,\symCount_{\symRegRange+1})$ where $\symIndexI < \symIndexJ$. Writing \eqref{equ:func} as 
\begin{multline}
\symFunc(\symX)
:=
\symCount_0 \symX
+
\symCount_1 \left(
\symHelper\!\left(\frac{x}{2^1}\right)
+\frac{\symX}{2^1}-1
\right)
+
\symCount_2 \left(
\symHelper\!\left(\frac{x}{2^2}\right)
+\frac{\symX}{2^2}-1
\right)
+
\ldots
\\
\dots
+
\symCount_\symRegRange
\left(
\symHelper\!\left(\frac{\symX}{2^\symRegRange}\right)
+\frac{\symX}{2^\symRegRange}-1
\right)
+
\symCount_{\symRegRange+1}
\left(
\symHelper\!\left(\frac{\symX}{2^{\symRegRange}}\right)
-1
\right).
\end{multline}
shows that the coefficient of $\symCount_\symIndexI$ is larger than the coefficient of $\symCount_\symIndexJ$ in case $\symIndexI < \symIndexJ$. Keeping $\symX$ fixed during an update decreases $\symFunc(\symX)$. As a consequence, since $\symFunc(\symX)$ is increasing, the new root and hence the estimate must be larger than before the update.

Note that \eqref{equ:funcdef} can be solved analytically for the special case $\symRegRange=0$ which corresponds to the already mentioned linear probabilistic counting algorithm. In this case, the maximum likelihood method under the Poisson model directly leads to the estimator presented in \cite{Whang1990} and which was also used for small range estimation \eqref{equ:small_range_estimate}. Despite the assumption of a Poisson model, it is a very good approximation of the optimal martingale estimator presented in \cite{Ting2014}. Due to this fact we could expect that maximum likelihood estimation under the Poisson model also works very well for the more  general HyperLogLog case.

\subsection{Inequalities for the maximum likelihood estimate}
In the following lower and upper bounds for $\symXEstimate$ are derived.
Applying Jensen's inequality on $\symHelper$ in \eqref{equ:func} gives an upper bound for $\symFunc(\symX)$:
\begin{equation}
\symFunc(\symX)
\leq
\symX
\sum_{\symRegVal=0}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}
+
\left(\symNumReg-\symCount_0\right)\cdot
\symHelper\left(
\symX\cdot
\left(
\sum_{\symRegVal=1}^{\symRegRange}
\frac{\symCount_\symRegVal}{2^\symRegVal}
+
\frac{\symCount_{\symRegRange+1}}{2^\symRegRange}
\right)\right)
-
\left(\symNumReg-\symCount_0\right).
\end{equation}
The left-hand side is zero, if $\symXEstimate$ is inserted. Resolution for $\symXEstimate$ finally gives the lower bound
\begin{equation}
\label{equ:strong_lower_bound}
\symXEstimate\geq \frac{\symNumReg-\symCount_0}{\sum_{\symRegVal=1}^{\symRegRange}
\frac{\symCount_\symRegVal}{2^\symRegVal}
+
\frac{\symCount_{\symRegRange+1}}{2^\symRegRange}
}
\log\left(
1
+
\frac{\sum_{\symRegVal=1}^{\symRegRange}
\frac{\symCount_\symRegVal}{2^\symRegVal}
+
\frac{\symCount_{\symRegRange+1}}{2^\symRegRange}
}
{
\sum_{\symRegVal=0}^{\symRegRange}
\frac{\symCount_\symRegVal}{2^\symRegVal}
}
\right).
\end{equation}
This bound can be weakened using $\log(1+x) \geq \frac{2x}{x+2}$ for $x\geq0$ which results in
\begin{equation}
\label{equ:weak_lower_bound}
\symXEstimate
\geq
\frac{\symNumReg-\symCount_0}
{\symCount_0+\frac{3}{2}\sum_{\symRegVal=1}^{\symRegRange}\frac{\symCount_\symRegVal}{2^\symRegVal} + \frac{\symCount_{\symRegRange+1}}{2^\symRegRange}}.
\end{equation}
Using the monotonicity of $\symHelper$, the lower bound
\begin{equation}
\symFunc(\symX)
\geq
\symX\sum_{\symRegVal=0}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}+
\sum_{\symRegVal=1}^\symRegRange \symCount_\symRegVal\symHelper\left(\frac{\symX}{2^{\symRegVal'_\text{max}}}\right)
+
\symCount_{\symRegRange+1}\symHelper\left(\frac{\symX}{2^{\symRegVal'_\text{max}}}\right)
-
\left(\symNumReg-\symCount_0\right),
\end{equation}
for $\symFunc$ can be found, where $\symRegVal'_\text{max} := \min(\symRegVal_\text{max}, \symRegRange)$ and
$\symRegVal_\text{max} := \max\lbrace \symRegVal\vert\symCount_\symRegVal>0\rbrace$.
Again, inserting $\symXEstimate$ and transformation gives
\begin{equation}
\label{equ:strong_upper_bound}
\symXEstimate
\leq
2^{\symRegVal'_\text{max}}
\log\left(
1+
\frac{\symNumReg-\symCount_0}
{
2^{\symRegVal'_\text{max}}
\sum_{\symRegVal=0}^{\symRegRange}
\frac{\symCount_\symRegVal}{2^\symRegVal}
}
\right)
\end{equation}
as upper bound which can be weakened using $\log(1+\symX)\leq \symX$ for $\symX\geq 0$
\begin{equation}
\label{equ:weak_upper_bound}
\symXEstimate
\leq
\frac{\symNumReg-\symCount_0}
{\sum_{\symRegVal=0}^{\symRegRange}
\frac{\symCount_\symRegVal}{2^\symRegVal}}.
\end{equation}
Note, if the HyperLogLog sketch is in the intermediate range, where $\symCount_0=\symCount_{\symRegRange+1}=0$ the bounds \eqref{equ:weak_lower_bound} and \eqref{equ:weak_upper_bound} differ only by a constant factor from the raw estimate \eqref{equ:intermediate_estimate}. Hence, the maximum likelihood method leads directly to the harmonic mean that is used by the raw estimator. If $\symCount_0>0$ or $\symCount_{\symRegRange+1}>0$ the bounds do no longer follow the harmonic mean and this is also the reason why the raw estimator fails for small and large cardinalities.

\subsection{Computation of the maximum likelihood estimate}
Since $\symFunc$ is concave and increasing, both, Newton-Raphson iteration and the secant method, converge to the root, if the function is negative for the starting points. In the following we start from the secant method to derive the new cardinality estimation algorithm. Even though the secant method has the disadvantage of slower convergence, a single iteration is simpler to calculate as it does not require the evaluation of the first derivative.

An iteration step of the secant method can be written as
\begin{equation}
\symX_{\symIndexI} = 
\symX_{\symIndexI-1} -
\left(\symX_{\symIndexI-1}-\symX_{\symIndexI-2}\right)
\frac{\symFunc(\symX_{\symIndexI-1})}{\symFunc(\symX_{\symIndexI-1}) - \symFunc(\symX_{\symIndexI-2})}
\end{equation}
If $\symX_0 = 0$ with $\symFunc(\symX_0)=-\left(\symNumReg-\symCount_0\right)$, and $\symX_1$ is equal to one of the derived lower bounds \eqref{equ:strong_lower_bound} or \eqref{equ:weak_lower_bound}, the sequence $\lbrace\symX_\symIndexI\rbrace$ is montone increasing. Using the definitions
\begin{equation}
\Delta\symX_\symIndexI := \symX_\symIndexI-\symX_{\symIndexI-1}
\end{equation}
and
\begin{equation}
\label{equ:funcprime}
\symFuncPrime(\symX):=\symFunc(\symX) + \left(\symNumReg-\symCount_0\right)
=\symX\sum_{\symRegVal=0}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}+
\sum_{\symRegVal=1}^\symRegRange \symCount_\symRegVal\symHelper\!\left(\frac{\symX}{2^\symRegVal}\right)
+
\symCount_{\symRegRange+1}\symHelper\!\left(\frac{\symX}{2^\symRegRange}\right)
\end{equation}
the iteration scheme can also be written as
\begin{gather}
\label{equ:secant_delta}
\Delta\symX_{\symIndexI} = \Delta\symX_{\symIndexI-1}
\frac{\left(\symNumReg-\symCount_0\right)-\symFuncPrime(\symX_{\symIndexI-1})}{\symFuncPrime(\symX_{\symIndexI-1}) - \symFuncPrime(\symX_{\symIndexI-2})}\\
\symX_{\symIndexI} = \symX_{\symIndexI-1} + \Delta\symX_{\symIndexI}
\end{gather}
The iteration can be stopped, if $\Delta\symX_{\symIndexI} \leq \symStopDelta\cdot \symX_{\symIndexI}$. Since the expected statistical errror for the HyperLogLog data structure scales according to $\frac{1}{\sqrt{\symNumReg}}$ \cite{Flajolet2007}, it makes sense to choose $\symStopDelta = \frac{\symStopEpsilon}{\sqrt{\symNumReg}}$ with some constant $\symStopEpsilon$. For all following results we have used $\symStopEpsilon = 10^{-2}$.

\subsection{Maximum-likelihood estimation algorithm}
In order to get a fast cardinality estimation algorithm, it is crucial to minimize the evaluation costs for \eqref{equ:funcprime}. A couple of optimizations allow significant reduction of the computational effort:
\begin{itemize}
\item Only a fraction of all count values $\symCount_\symRegVal$ is non-zero. If we denote $\symRegVal_\text{min}:=\min\lbrace \symRegVal\vert\symCount_\symRegVal>0\rbrace$ and $\symRegVal_\text{max}:=\max\lbrace \symRegVal\vert\symCount_\symRegVal>0\rbrace$,  it is sufficient to loop over all indices in the range $[\symRegVal_\text{min}, \symRegVal_\text{max}]$.
\item The coefficient of the linear term $\sum_{\symRegVal=0}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}$ can be precalculated and reused for all function evaluations.
\item Many programming languages allow the efficient multiplication and division by any integral power of 2 using special functions, such as \texttt{ldexp} in C/C++ or \texttt{scalb} in Java.
\item The function $\symHelper(\symX)$ only needs to be evaluated at values $\lbrace\frac{\symX}{2^{\symRegVal'_\text{max}}},\frac{\symX}{2^{\symRegVal'_\text{max}-1}}\ldots,\frac{\symX}{2^{\symRegVal_\text{min}}}\rbrace$ where $\symRegVal'_\text{max} := \min(\symRegVal_\text{max}, \symRegRange)$. This series corresponds to a geometric series with ratio 2. A straightforward calculation using \eqref{equ:helper} is very expensive because of the exponential function. However, if we already know $\symHelper\left(\frac{\symX}{2^{\symRegVal'_\text{max}}}\right)$ all other required function values can be easily obtained using the identity
\begin{equation}
\label{equ:helper_recursion1}
\symHelper\left(2\symX\right) = \frac{\symX+2\symHelper\left(\symX\right)\left(1-\symHelper\left(\symX\right)\right)}{\symX+2\left(1-\symHelper\left(\symX\right)\right)}
\end{equation}
or
\begin{equation}
\label{equ:helper_recursion2}
\symHelper\left(\frac{\symX}{2^{\symRegVal}}\right) = \frac{\frac{\symX}{2^{\symRegVal+2}}+\symHelper\left(\frac{\symX}{2^{\symRegVal+1}}\right)\left(1-\symHelper\left(\frac{\symX}{2^{\symRegVal+1}}\right)\right)}{\frac{\symX}{2^{\symRegVal+2}}+\left(1-\symHelper\left(\frac{\symX}{2^{\symRegVal+1}}\right)\right)}
\end{equation}
Note, this recursive formula is stable in a sense that the relative error of $\symHelper\left(2\symX\right)$ is smaller than that of $\symHelper\left(\symX\right)$ as shown in \cref{app:helper_stable}.

\item If $\symHelper\left(\frac{\symX}{2^{\symRegVal'_\text{max}}}\right)$ is smaller than 0.5, the function $\symHelper(\symX)$ can be well approximated by a Taylor series around $\symX=0$
\begin{equation}
\symHelper(\symX)
=
\frac{\symX}{2} - \frac{\symX^2}{12} +\frac{\symX^4}{720}-\frac{\symX^6}{30240} + \symBigO(\symX^{8})
\end{equation}
which can be optimized for numerical evaluation using Estrin's scheme and $\symX' := \frac{\symX}{2}$ and $\symX'' := \symX' \symX'$
\begin{equation}
\label{equ:taylor}
\symHelper(\symX)
=
\symX' - \symX''/3 + \left(\symX'' \symX''\right)\left(1/45-\symX''/472.5\right)
+ \symBigO(\symX^{8})
\end{equation}
In fact, $\symHelper\left(\frac{\symX}{2^{\symRegVal'_\text{max}}}\right)\leq 0.5$ is almost always fulfilled as long as registers are not saturated. Using \eqref{equ:strong_upper_bound} it is straightforward to see that $\frac{\symX}{2^{\symRegVal'_\text{max}}} \leq \log 2 \approx 0.693$, if $\symCount_{\symRegRange+1}=0$.
In case $\frac{\symX}{2^{\symRegVal'_\text{max}}} > 0.5$, the value $\frac{\symX}{2^{\symE+1}}$ is taken instead, where $\symE$ is the exponent of the floating point representation of $\symX$, $\symE = 1+\lfloor\log_2(\symX)\rfloor$. By definition, $\frac{\symX}{2^{\symE+1}}\leq 0.5$ which allows using the Taylor approximation. $\symHelper\left(\frac{\symX}{2^{\symRegVal'_\text{max}}}\right)$ is finally obtained after $\symE + 1 -\symRegVal'_\text{max}$ iterations using \eqref{equ:helper_recursion2}.
\end{itemize}

All these optimizations together finally give the new cardinality estimation algorithm presented in \cref{alg:estimate_ml}.

\begin{algorithm}
\caption{Cardinality estimation}
\ContinuedFloat
\label{alg:estimate_ml}
\begin{algorithmic}
\Function {EstimateCardinality}{$\vec{\symCount}$}
\State $\symRegRange\gets\dim(\vec{\symCount})-2$
\State $\symRegVal_\text{min} \gets \min\lbrace \symRegVal\vert\symCount_\symRegVal>0\rbrace$
\If{$\symRegVal_\text{min} > \symRegRange$}
\State\Return $\infty$
\EndIf
\State $\symRegVal'_\text{min} \gets \max(\symRegVal_\text{min}, 1)$
\State $\symRegVal_\text{max} \gets \max\lbrace \symRegVal\vert\symCount_\symRegVal>0\rbrace$
\State $\symRegVal'_\text{max} \gets \min(\symRegVal_\text{max}, \symRegRange)$
\State $\symZ \gets 0$
\State $\symNumReg'\gets \symCount_{\symRegRange+1}$
\State $\symY \gets 2^{-\symRegVal'_\text{max}}$
\For{$\symRegVal \gets \symRegVal'_\text{max},\symRegVal'_\text{min}$}
\State $\symZ \gets \symZ + \symCount_\symRegVal\cdot\symY$
\Comment here $\symY = 2^{-\symRegVal}$
\State $\symY \gets 2\symY$
\State $\symNumReg'\gets\symNumReg' + \symCount_\symRegVal$
\EndFor
\State $\symNumReg \gets \symNumReg' + \symCount_0$ 
\State $\symCount' \gets \symCount_{\symRegRange+1}$
\If{$\symRegRange\geq 1$}
\State $\symCount' \gets \symCount' + \symCount_{\symRegVal'_\text{max}}$
\EndIf
\State $\symFuncPrime_\text{prev}\gets 0$
\State $\symA\gets \symZ + \symCount_0$
\State $\symB\gets \symZ + 
\symCount_{\symRegRange+1}\cdot 2^{-\symRegRange}$
\If{$\symB \leq 1.5\cdot\symA$}
\State $\symX \gets \symNumReg'/(0.5\cdot \symB+\symA)$ \Comment weak lower bound \eqref{equ:weak_lower_bound}
\Else
\State $\symX \gets \symNumReg'/b \cdot \log(1+\symB/\symA)$ \Comment strong lower bound \eqref{equ:strong_lower_bound}
\EndIf
\algstore{myalg}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Cardinality estimation (continued)}
\begin{algorithmic}
\algrestore{myalg}
\State $\Delta\symX \gets \symX$
\While{$\Delta\symX > \symX\cdot\symError$} \Comment secant method iteration, $\symStopEpsilon = 10^{-2}$
\State $\symE \gets 1+\lfloor\log_2(\symX)\rfloor$
\State $\symXNormalized \gets
\symX \cdot 2^{-\max(\symRegVal'_\text{max}+1, \symE+2)}$
\Comment $\symXNormalized \in [0, 0.25]$
\State $\symX''\gets \symXNormalized\cdot\symXNormalized$
\State $\symHelper \gets
\symX' - \symX''/3 + \left(\symX''\cdot \symX''\right)\cdot\left(1/45-\symX''/472.5\right)$
\Comment Taylor approximation \eqref{equ:taylor}
\For{$\symRegVal\gets \symE,\symRegVal'_\text{max}$}
\State $\symHelper \gets \frac{\symXNormalized+\symHelper\cdot(1-\symHelper)}{\symXNormalized+(1-\symHelper)}$
\Comment calculate $\symHelper\left(\frac{\symX}{2^{\symRegVal}}\right)$, see \eqref{equ:helper_recursion2}, at this point $\symXNormalized = \frac{\symX}{2^{\symRegVal+2}}$
\State $\symXNormalized \gets 2\symXNormalized$
\EndFor
\State $\symFuncPrime \gets \symCount'\cdot\symHelper$
\Comment compare \eqref{equ:funcprime}
\For{$\symRegVal\gets(\symRegVal'_\text{max}-1),\symRegVal'_\text{min}$}
\State $\symHelper \gets \frac{\symXNormalized+\symHelper\cdot(1-\symHelper)}{\symXNormalized+(1-\symHelper)}$
\Comment calculate $\symHelper\left(\frac{\symX}{2^{\symRegVal}}\right)$, see \eqref{equ:helper_recursion2}, at this point $\symXNormalized = \frac{\symX}{2^{\symRegVal+2}}$
\State $\symFuncPrime\gets \symFuncPrime + \symCount_\symRegVal\cdot\symHelper$
\State $\symXNormalized \gets 2\symXNormalized$
\EndFor
\State $\symFuncPrime\gets \symFuncPrime + \symX\cdot\symA$
\If{$\symFuncPrime > \symFuncPrime_\text{prev} \wedge \symNumReg' \geq\symFuncPrime$}
\State $\Delta\symX \gets \Delta\symX \cdot \frac{\symNumReg' - \symFuncPrime}{\symFuncPrime - \symFuncPrime_\text{prev}}$
\Comment see \eqref{equ:secant_delta}
\Else
\State $\Delta\symX \gets 0$
\EndIf
\State $\symX \gets \symX + \Delta\symX$
\State $\symFuncPrime_\text{prev}\gets \symFuncPrime$
\EndWhile
\State \Return $\symNumReg\cdot\symX$
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Estimation error}
In order to verify the new estimation algorithm, we generated 10\,000 HyperLogLog sketches and inserted up to 50 billion unique elements. Element hash values have been mocked by random numbers. For the following results we used the Mersenne Twister random number generator with 19937 bit state size from the C++ standard library.

\cref{fig:estimation_error_12_20} shows the distribution of the relative error of the estimated cardinality using \cref{alg:estimate_ml} compared to the true cardinality for $\symPrecision=12$ and $\symRegRange=20$. As the median shows, the error is essentially unbiased over the entire cardinality range except for very small values. The new approach is able to accurately estimate cardinalities up to 4 billions ($\approx 2^{\symPrecision+\symRegRange}$) which is about an order of magnitude larger than the operating range upper bound of the raw estimate (\cref{fig:raw_estimate}) or the original method (\cref{fig:original_estimate}).

\begin{figure}
\centering
\includesvg[width=1\textwidth]{max_likelihood_estimate_12_20}
\caption{Relative estimation error as a function of the true cardinality for a HyperLogLog sketch with parameters $\symPrecision = 12$ and $\symRegRange=20$.}
\label{fig:estimation_error_12_20}
\end{figure}

The new estimation algorithm also works well for other HyperLogLog configurations. First we considered the original HyperLogLog algorithm that used a 32-bit hash function ($\symPrecision + \symRegRange = 32$). The relative estimation error for precisions $\symPrecision=8$, $\symPrecision=16$, $\symPrecision=22$ are shown in \cref{fig:estimation_error_8_24}, \cref{fig:estimation_error_16_16}, and \cref{fig:estimation_error_22_10}, respectively. As expected, since  $\symPrecision + \symRegRange = 32$ is kept constant, the operating range remains more or less the same, while the relative error decreases with increasing precision. Again, the new algorithm gives inherently unbiased estimates.

\begin{figure}
\centering
\includesvg[width=1\textwidth]{max_likelihood_estimate_8_24}
\caption{Relative estimation error as a function of the true cardinality for a HyperLogLog sketch with parameters $\symPrecision = 8$ and $\symRegRange=24$.}
\label{fig:estimation_error_8_24}
\end{figure}

\begin{figure}
\centering
\includesvg[width=1\textwidth]{max_likelihood_estimate_16_16}
\caption{Relative estimation error as a function of the true cardinality for a HyperLogLog sketch with parameters $\symPrecision = 16$ and $\symRegRange=16$.}
\label{fig:estimation_error_16_16}
\end{figure}

\begin{figure}
\centering
\includesvg[width=1\textwidth]{max_likelihood_estimate_22_10}
\caption{Relative estimation error as a function of the true cardinality for a HyperLogLog sketch with parameters $\symPrecision = 22$ and $\symRegRange=10$.}
\label{fig:estimation_error_22_10}
\end{figure}

As proposed in \cite{Heule2013}, the operating range can be extended by
replacing the 32-bit hash function by a 64-bit hash function. \cref{fig:estimation_error_12_52} shows the relative error for such a HyperLogLog configuration with precision  $\symPrecision=12$. In this case, in order to use all the 64 bits of the hash value, $\symRegRange$ must be chosen to be equal to $64 - \symPrecision = 52$. As a consequence, in order to represent the maximum possible register value $\symRegRange+1 = 53$, 6 bits are needed for each register. The doubled hash value size shifts the maximum trackable cardinality value towards $2^{64}$. As \cref{fig:estimation_error_12_52} shows, when compared to the 32-bit hash value case given in \cref{fig:estimation_error_12_20}, the estimation error remains constant over the entire simulated cardinality range up to 50 billions.

\begin{figure}
\centering
\includesvg[width=1\textwidth]{max_likelihood_estimate_12_52}
\caption{Relative estimation error as a function of the true cardinality for a HyperLogLog sketch with parameters $\symPrecision = 12$ and $\symRegRange=52$.}
\label{fig:estimation_error_12_52}
\end{figure}

We also evaluated the case $\symPrecision = 12$ and $\symRegRange=14$, which is interesting, because the register values are limited to the range $[0, 15]$. As a consequence, 4 bits are sufficient for representing a single register value. This allows two registers to share a single byte, which is beneficial from a performance perspective. Nevertheless, this configuration still allows the estimation of cardinalities up to 100 millions as shown in \cref{fig:estimation_error_12_14}, which could be enough for many applications.

\begin{figure}
\centering
\includesvg[width=1\textwidth]{max_likelihood_estimate_12_14}
\caption{Relative estimation error as a function of the true cardinality for a HyperLogLog sketch with parameters $\symPrecision = 12$ and $\symRegRange=14$.}
\label{fig:estimation_error_12_14}
\end{figure}

\subsection{Performance}
In order to prove that the new algorithm is not only accurate, but also fast, we investigated the average computation time for estimating the cardinality from a given HyperLogLog sketch. For different cardinalities we loaded the multiplicity vectors of 1000 precalculated and randomly generated HyperLogLog sketches into main memory. The average computation time was determined by cycling over these multiplicity vectors and passing them as input to the new estimation algorithm. For each evaluated cardinality value the average execution time was calculated after 100 cycles which corresponds to 100\,000 algorithm executions. The results for HyperLogLog configurations $\symPrecision=12, \symRegRange=20$ and $\symPrecision=12, \symRegRange=52$ are shown in \cref{fig:avg_exec_time}. All these benchmarks where carried out on an Intel Core i5-2500K clocking at 3.3GHz. As can be seen, the average calculation time did never exceed 700\,ns. 

The numbers do not yet include the required processing time to calculate the multiplicity vector from the HyperLogLog sketch, which requires a complete scan over all registers and counting the different register values into an array. A theoretical lower bound for this processing time can be derived using the maximum memory bandwidth of the CPU, which is 21\,GB/s for an Intel Core i5-2500K. For precision $\symPrecision=12$ there are 4096 registers, each of them requires at least 5 bits. Hence, the total data size of the HyperLogLog sketch is 2.5\,kB minimum and transfer time from main memory to CPU will be at least 120\,ns. Having this value in mind, the presented processing time numbers are quite satisfying.

\begin{figure}
\centering
\includesvg[width=1\textwidth]{max_likelihood_avg_exec_time}
\caption{Average computation time as a function of the true cardinality with an Intel Core i5-2500K clocking at 3.3GHz when estimating the cardinality from HyperLogLog sketches with parameters $\symPrecision=12$, $\symRegRange=20$ and $\symPrecision=12$, $\symRegRange=52$, respectively.}
\label{fig:avg_exec_time}
\end{figure}

\section{Cardinality estimation of set intersections and differences}
Assume two different sets $\symSetS_1$ and $\symSetS_2$ that have been recorded by two HyperLogLog sketches with same parameters $(\symPrecision,\symRegRange)$. Given the corresponding register values $\vec{\symRegVal}_1$ and
$\vec{\symRegVal}_2$, we attempt to estimate the cardinalities of the pair-wise disjoint sets $\symSetX = \symSetS_1\cap\symSetS_2$, $\symSetA = \symSetS_1\setminus\symSetS_2$, and $\symSetB = \symSetS_2\setminus\symSetS_1$. Motivated by the good results we have obtained for cardinality estimation of a single HyperLogLog sketch, we want to get these estimates using the maximum likelihood method applied to the joint probability distribution of $\vec{\symRegVal}_1$ and $\vec{\symRegVal}_2$.

Under the Poisson model the register values are independent and identically distributed. Therefore, we first derive the joint probability distribution for a single register that has value $\symRegValVariate_1$ in the first HyperLogLog sketch representing $\symSetS_1$ and value $\symRegValVariate_2$ in the second HyperLogLog sketch representing $\symSetS_2$. 

The HyperLogLog sketch that represents $\symSetS_1$ could have also been obtained by constructing two HyperLogLog sketches from sets $\symSetA$ and $\symSetX$ and by merging both by taking for each register the maximum value of both sketches. Analogously, the HyperLogLog sketch for $\symSetS_2$ could have been obtained from sketches for $\symSetB$ and $\symSetX$. Let us consider the register values $\symRegValVariate_\symSetASuffix$, $\symRegValVariate_\symSetBSuffix$, and $\symRegValVariate_\symSetXSuffix$ at a certain position of the HyperLogLog sketches for $\symSetA$, $\symSetB$, and $\symSetX$, respectively. The corresponding values in sketches for $\symSetS_1$ and $\symSetS_2$ are given by
\begin{equation}
\symRegValVariate_1 = \max\left(\symRegValVariate_\symSetASuffix, \symRegValVariate_\symSetXSuffix\right)
,\quad
\symRegValVariate_2 = \max\left(\symRegValVariate_\symSetBSuffix, \symRegValVariate_\symSetXSuffix\right)
\end{equation}
Their joint cumulative probability function is given as
\begin{align}
\symProbability\left(
\symRegValVariate_1 \leq \symRegVal_1
\wedge
\symRegValVariate_2 \leq \symRegVal_2
\right)
&=
\symProbability\left(
\max\left(\symRegValVariate_\symSetASuffix, \symRegValVariate_\symSetXSuffix\right) \leq \symRegVal_1
\wedge
\max\left(\symRegValVariate_\symSetBSuffix, \symRegValVariate_\symSetXSuffix\right) \leq \symRegVal_2
\right)
\nonumber\\
&=
\symProbability
\left(
\symRegValVariate_\symSetASuffix \leq \symRegVal_1
\wedge
\symRegValVariate_\symSetBSuffix \leq \symRegVal_2
\wedge
\symRegValVariate_\symSetXSuffix \leq \min\left(\symRegVal_1, \symRegVal_2\right)
\right)
\nonumber\\
&=
\symProbability
\left(
\symRegValVariate_\symSetASuffix \leq \symRegVal_1
\right)
\symProbability
\left(
\symRegValVariate_\symSetBSuffix \leq \symRegVal_2
\right)
\symProbability
\left(
\symRegValVariate_\symSetXSuffix \leq \min\left(\symRegVal_1, \symRegVal_2\right)
\right)
\end{align}
Here the last transformation used the independence of $\symRegValVariate_\symSetASuffix$, $\symRegValVariate_\symSetBSuffix$, and $\symRegValVariate_\symSetXSuffix$, because by definition, the sets $\symSetA$, $\symSetB$, and $\symSetX$ are disjoint. Furthermore, under the Poisson model $\symRegValVariate_\symSetASuffix$, $\symRegValVariate_\symSetBSuffix$, and $\symRegValVariate_\symSetXSuffix$ obey 
\eqref{equ:register_value_distribution}. If we assume that elements are added to $\symSetA$, $\symSetB$, and $\symSetX$ at rates $\symPoissonRate_\symSetXSuffix$, $\symPoissonRate_\symSetASuffix$, and $\symPoissonRate_\symSetBSuffix$, respectively, the probability that a certain register has a value less than or equal to $\symRegVal_1$ in the first HyperLogLog sketch and simultaneously a value less than or equal to $\symRegVal_2$ in the second one can be written as
\begin{equation}
\symProbability(
\symRegValVariate_1 \leq \symRegVal_1
\wedge
\symRegValVariate_2 \leq \symRegVal_2
)
=\begin{cases}
0 & \symRegVal_1 < 0 \vee \symRegVal_2 < 0
\\
e^{
-
\frac{\symPoissonRate_{\symSetASuffix}}{\symNumReg 2^{\symRegVal_1}}
-
\frac{\symPoissonRate_{\symSetBSuffix}}{\symNumReg 2^{\symRegVal_2}}
-
\frac{\symPoissonRate_{\symSetXSuffix}}{\symNumReg 2^{\min(\symRegVal_1, \symRegVal_2)}}
}
& 0\leq\symRegVal_1 \leq \symRegRange \wedge 0\leq\symRegVal_2\leq\symRegRange
\\
e^{
-
\frac{\symPoissonRate_{\symSetBSuffix} + \symPoissonRate_{\symSetXSuffix}}{\symNumReg 2^{\symRegVal_2}}
}
& 0\leq\symRegVal_2 \leq \symRegRange < \symRegVal_1
\\
e^{
-
\frac{\symPoissonRate_{\symSetASuffix} + \symPoissonRate_{\symSetXSuffix}}{\symNumReg 2^{\symRegVal_1}}
}
&  0\leq\symRegVal_1 \leq \symRegRange < \symRegVal_2
\\
1
&
\symRegRange < \symRegVal_1=\symRegVal_2
\end{cases}
\end{equation}

The joint probability mass function for both register values can be calculated using
\begin{multline}
\symProbabilityMass(\symRegVal_1,\symRegVal_2)
=
\symProbability(
\symRegValVariate_1 \leq \symRegVal_1
\wedge
\symRegValVariate_2 \leq \symRegVal_2
)
-
\symProbability(
\symRegValVariate_1 \leq \symRegVal_1-1
\wedge
\symRegValVariate_2 \leq \symRegVal_2
)
\\
-\symProbability(
\symRegValVariate_1 \leq \symRegVal_1
\wedge
\symRegValVariate_2 \leq \symRegVal_2-1
)
+\symProbability(
\symRegValVariate_1 \leq \symRegVal_1-1
\wedge
\symRegValVariate_2 \leq \symRegVal_2-1
)
\end{multline}
which finally gives
\begin{multline}
\label{equ:register_value_joint_pmf}
\symProbabilityMass(\symRegVal_1,\symRegVal_2)
=
\\
\begin{cases}
e^{-\frac{\symPoissonRate_\symSetASuffix + \symPoissonRate_\symSetXSuffix}
{\symNumReg }
-\frac{\symPoissonRate_\symSetBSuffix}{\symNumReg 2^{\symRegVal_2}}
}
\left(
1-
e^{
-\frac{\symPoissonRate_\symSetBSuffix}{\symNumReg 2^{\symRegVal_2}}
}
\right)
&
0 = \symRegVal_1 < \symRegVal_2 \leq \symRegRange
\\
e^{-\frac{\symPoissonRate_\symSetASuffix + \symPoissonRate_\symSetXSuffix}
{\symNumReg}
}
\left(
1-
e^{
-\frac{\symPoissonRate_\symSetBSuffix}{\symNumReg 2^{\symRegRange}}
}
\right)
&
0 = \symRegVal_1 < \symRegVal_2 = \symRegRange + 1
\\
e^{-\frac{\symPoissonRate_\symSetASuffix + \symPoissonRate_\symSetXSuffix}
{\symNumReg 2^{\symRegVal_1}}
-\frac{\symPoissonRate_\symSetBSuffix}{\symNumReg 2^{\symRegVal_2}}
}
\left(
1-
e^{-\frac{\symPoissonRate_\symSetASuffix + \symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\symRegVal_1}}
}
\right)
\left(
1-
e^{
-\frac{\symPoissonRate_\symSetBSuffix}{\symNumReg 2^{\symRegVal_2}}
}
\right)
&
1 \leq \symRegVal_1 < \symRegVal_2 \leq \symRegRange
\\
e^{-\frac{\symPoissonRate_\symSetASuffix + \symPoissonRate_\symSetXSuffix}
{\symNumReg 2^{\symRegVal_1}}
}
\left(
1-
e^{-\frac{\symPoissonRate_\symSetASuffix + \symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\symRegVal_1}}
}
\right)
\left(
1-
e^{
-\frac{\symPoissonRate_\symSetBSuffix}{\symNumReg 2^{\symRegRange}}
}
\right)
&
1 \leq \symRegVal_1 < \symRegVal_2 = \symRegRange + 1
\\
e^{-\frac{\symPoissonRate_\symSetBSuffix + \symPoissonRate_\symSetXSuffix}
{\symNumReg }
-\frac{\symPoissonRate_\symSetASuffix}{\symNumReg 2^{\symRegVal_1}}
}
\left(
1-
e^{
-\frac{\symPoissonRate_\symSetASuffix}{\symNumReg 2^{\symRegVal_1}}
}
\right)
&
0 = \symRegVal_2 < \symRegVal_1 \leq \symRegRange
\\
e^{-\frac{\symPoissonRate_\symSetBSuffix + \symPoissonRate_\symSetXSuffix}
{\symNumReg}
}
\left(
1-
e^{
-\frac{\symPoissonRate_\symSetASuffix}{\symNumReg 2^{\symRegRange}}
}
\right)
&
0 = \symRegVal_2 < \symRegVal_1 = \symRegRange + 1
\\
e^{-\frac{\symPoissonRate_\symSetBSuffix + \symPoissonRate_\symSetXSuffix}
{\symNumReg 2^{\symRegVal_2}}
-\frac{\symPoissonRate_\symSetASuffix}{\symNumReg 2^{\symRegVal_1}}
}
\left(
1-
e^{-\frac{\symPoissonRate_\symSetBSuffix + \symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\symRegVal_2}}
}
\right)
\left(
1-
e^{
-\frac{\symPoissonRate_\symSetASuffix}{\symNumReg 2^{\symRegVal_1}}
}
\right)
&
1 \leq \symRegVal_2 < \symRegVal_1 \leq \symRegRange
\\
e^{-\frac{\symPoissonRate_\symSetBSuffix + \symPoissonRate_\symSetXSuffix}
{\symNumReg 2^{\symRegVal_2}}
}
\left(
1-
e^{-\frac{\symPoissonRate_\symSetBSuffix + \symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\symRegVal_2}}
}
\right)
\left(
1-
e^{
-\frac{\symPoissonRate_\symSetASuffix}{\symNumReg 2^{\symRegRange}}
}
\right)
&
1 \leq \symRegVal_2 < \symRegVal_1 = \symRegRange + 1
\\
e^{-\frac{\symPoissonRate_\symSetASuffix + \symPoissonRate_\symSetBSuffix + \symPoissonRate_\symSetXSuffix}
{\symNumReg}
}
&
0 = \symRegVal_1 = \symRegVal_2
\\
e^{-\frac{\symPoissonRate_\symSetASuffix + \symPoissonRate_\symSetBSuffix + \symPoissonRate_\symSetXSuffix}
{\symNumReg 2^\symRegVal}
}
\left(
1
-
e^{-\frac{\symPoissonRate_\symSetASuffix +  \symPoissonRate_\symSetXSuffix}
{\symNumReg 2^\symRegVal}
}
-
e^{-\frac{\symPoissonRate_\symSetBSuffix + \symPoissonRate_\symSetXSuffix}
{\symNumReg 2^\symRegVal}
}
+
e^{-\frac{\symPoissonRate_\symSetASuffix + \symPoissonRate_\symSetBSuffix + \symPoissonRate_\symSetXSuffix}
{\symNumReg 2^\symRegVal}
}
\right)
&
1 \leq \symRegVal_1 = \symRegVal_2 = \symRegVal\leq \symRegRange
\\
1
-
e^{-\frac{\symPoissonRate_\symSetASuffix +  \symPoissonRate_\symSetXSuffix}
{\symNumReg 2^\symRegRange}
}
-
e^{-\frac{\symPoissonRate_\symSetBSuffix + \symPoissonRate_\symSetXSuffix}
{\symNumReg 2^\symRegRange}
}
+
e^{-\frac{\symPoissonRate_\symSetASuffix + \symPoissonRate_\symSetBSuffix + \symPoissonRate_\symSetXSuffix}
{\symNumReg 2^\symRegRange}
}
&
\symRegVal_1 = \symRegVal_2 = \symRegRange + 1
\end{cases}
\end{multline}

The logarithm of the joint probability mass function can be written using Iverson bracket notation ($\left[\text{true}\right]:=1$, $\left[\text{false}\right]:=0$) as
\begin{align}
\label{equ:joint_log_pmf_single_register}
\log(\symProbabilityMass(\symRegVal_1,\symRegVal_2))
=&
-\frac{\symPoissonRate_\symSetASuffix}{\symNumReg 2^{\symRegVal_1}}
\left[\symRegVal_1\leq\symRegRange\right]
-
\frac{\symPoissonRate_\symSetBSuffix}{\symNumReg 2^{\symRegVal_2}}
\left[\symRegVal_2\leq\symRegRange\right]
-
\frac{\symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\min\left(\symRegVal_1,\symRegVal_2\right)}}
\left[\symRegVal_1\leq\symRegRange\vee\symRegVal_2\leq\symRegRange\right]
\nonumber\\
&
+
\log\left(1-e^{-\frac{\symPoissonRate_\symSetASuffix+\symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\symRegVal_1}}}\right)
\left[1\leq\symRegVal_1<\symRegVal_2\right]
\nonumber\\
&
+
\log\left(1-e^{-\frac{\symPoissonRate_\symSetASuffix}{\symNumReg 2^{\min\left(\symRegVal_1, \symRegRange\right)}}}\right)
\left[\symRegVal_2<\symRegVal_1\right]
\nonumber\\
&
+
\log\left(1-e^{-\frac{\symPoissonRate_\symSetBSuffix+\symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\symRegVal_2}}}\right)
\left[1\leq\symRegVal_2<\symRegVal_1\right]
\nonumber\\
&
+
\log\left(1-e^{-\frac{\symPoissonRate_\symSetBSuffix}{\symNumReg 2^{\min\left(\symRegVal_2, \symRegRange\right)}}}\right)
\left[\symRegVal_1<\symRegVal_2\right]
\nonumber\\
&
+
\log\left(
1
-e^{-\frac{\symPoissonRate_\symSetASuffix+\symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\min\left(\symRegVal_1, \symRegRange\right)}}}
-
e^{-\frac{\symPoissonRate_\symSetBSuffix+\symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\min\left(\symRegVal_1, \symRegRange\right)}}}
+
e^{-\frac{\symPoissonRate_\symSetASuffix+\symPoissonRate_\symSetBSuffix+\symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\min\left(\symRegVal_1, \symRegRange\right)}}}
\right)
\left[1\leq\symRegVal_1=\symRegVal_2\right]
\end{align}

Since under the Poisson model, the values for different registers are independent we are now able to write the joint probability mass function for the joint state of both HyperLogLog sketches
\begin{equation}
\symProbabilityMass(\vec{\symRegVal}_1,\vec{\symRegVal}_2)
=
\prod_{\symRegVal_1 = 0}^{\symRegRange+1}
\prod_{\symRegVal_2 = 0}^{\symRegRange+1}
\symProbabilityMass(\symRegVal_1,\symRegVal_2)
^{\symCount_{\symRegVal_1\symRegVal_2}}.
\end{equation}
Here we have used the multiplicity matrix $\symCountMatrix = \left(\symCount_{\symRegVal_1\symRegVal_2}\right)_{\symRegVal_1\symRegVal_2\in[0,\symRegRange+1]}$ defined by
\begin{equation}
\symCount_{\symRegVal_1\symRegVal_2}
:=
\left|\left\lbrace
\left(\symIndexI,\symIndexJ\right) \vert
\symRegVal_{\symIndexI,1} = \symRegVal_1
\wedge
\symRegVal_{\symIndexJ,2} = \symRegVal_2
\right\rbrace\right|
\end{equation}
As in \cref{sec:cardinality_estimation} where we found that the multiplicity vector $\vec{\symCount}$ of a sketch is a sufficient statistic for the cardinality, the multiplicity matrix of two sketches is a sufficient statistic for the cardinalities of $\symSetX$, $\symSetA$, and $\symSetB$.

In order to get the maximum likelihood estimates $\symPoissonRateEstimate_\symSetASuffix$,
 $\symPoissonRateEstimate_\symSetBSuffix$, and  $\symPoissonRateEstimate_\symSetXSuffix$ we need to maximize the log-likelihood function given by
\begin{equation}
\log \symLikelihood(
\symPoissonRate_\symSetASuffix,
\symPoissonRate_\symSetBSuffix,
\symPoissonRate_\symSetXSuffix
\vert
\vec{\symRegVal}_1,
\vec{\symRegVal}_2
)
=
\sum_{\symRegVal_1 = 0}^{\symRegRange+1}
\sum_{\symRegVal_2 = 0}^{\symRegRange+1}
\symCount_{\symRegVal_1\symRegVal_2}
\log(\symProbabilityMass(\symRegVal_1,\symRegVal_2))
\end{equation}
Insertion of \eqref{equ:joint_log_pmf_single_register} results in
\begin{align}
\label{equ:log_likelihood_pair}
\log \symLikelihood(
\symPoissonRate_\symSetASuffix,
\symPoissonRate_\symSetBSuffix,
\symPoissonRate_\symSetXSuffix
\vert
\vec{\symRegVal}_1,
\vec{\symRegVal}_2
)
=
&
-
\frac{\symPoissonRate_\symSetASuffix}{\symNumReg}
\sum_{\symRegVal=0}^{\symRegRange}
\frac{
  \symCount^\leftarrow_\symRegVal+
  \symCount_{\symRegVal\symRegVal}+
  \symCount^\rightarrow_\symRegVal
}{2^{\symRegVal}}
-
\frac{\symPoissonRate_\symSetBSuffix}{\symNumReg}
\sum_{\symRegVal=0}^{\symRegRange}
\frac{
  \symCount^\uparrow_\symRegVal+
  \symCount_{\symRegVal\symRegVal}+
  \symCount^\downarrow_\symRegVal
}{2^{\symRegVal}}
\nonumber\\
&
-
\frac{\symPoissonRate_\symSetXSuffix}{\symNumReg}
\sum_{\symRegVal=0}^{\symRegRange}
\frac{
  \symCount^\rightarrow_\symRegVal+
  \symCount_{\symRegVal\symRegVal}+
  \symCount^\downarrow_\symRegVal
}{2^{\symRegVal}}
\nonumber\\
&
+
\sum_{\symRegVal=1}^{\symRegRange+1}
\log\left(1-e^{-\frac{\symPoissonRate_\symSetASuffix+\symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}\right)
\symCount_\symRegVal^\rightarrow
+
\log\left(1-e^{-\frac{\symPoissonRate_\symSetASuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}\right)
\symCount_\symRegVal^\leftarrow
\nonumber\\
&
+
\sum_{\symRegVal=1}^{\symRegRange+1}
\log\left(1-e^{-\frac{\symPoissonRate_\symSetBSuffix+\symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}\right)
\symCount_\symRegVal^\downarrow
+
\log\left(1-e^{-\frac{\symPoissonRate_\symSetBSuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}\right)
\symCount_\symRegVal^\uparrow
\nonumber\\
&
+
\sum_{\symRegVal=1}^{\symRegRange+1}
\log\left(
1
-e^{-\frac{\symPoissonRate_\symSetASuffix+\symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}
-
e^{-\frac{\symPoissonRate_\symSetBSuffix+\symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}
+
e^{-\frac{\symPoissonRate_\symSetASuffix+\symPoissonRate_\symSetBSuffix+\symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}
\right)
\symCount_{\symRegVal\symRegVal}
\end{align}
which is the two HyperLogLog case analog of \eqref{equ:log_likelihood_single}.
The constants $\symCount^\uparrow_\symRegVal:=\sum_{\symIndexI=0}^{\symRegVal-1} \symCount_{\symIndexI\symRegVal}$, $\symCount^\rightarrow_\symRegVal:=\sum_{\symIndexI=\symRegVal+1}^{\symRegRange+1} \symCount_{\symRegVal\symIndexI}$, $\symCount^\downarrow_\symRegVal:=\sum_{\symIndexI=\symRegVal+1}^{\symRegRange+1} \symCount_{\symIndexI\symRegVal}$, and $\symCount^\leftarrow_\symRegVal:=\sum_{\symIndexI=0}^{\symRegVal-1} \symCount_{\symRegVal\symIndexI}$ correspond to sums within the multiplicity matrix, which are obtained by aggregating all elements that are in up, right, down, and left directions relative to the $\symRegVal$-th diagonal entry  $\symCount_{\symRegVal\symRegVal}$, respectively.

The log-likelihood function \eqref{equ:log_likelihood_pair} does not always have a strict global maximum point. For example, in case $\symCountMatrix$ is a strict lower triangular matrix which corresponds to the case that each register of the first HyperLogLog sketch is larger than the corresponding value in the second HyperLogLog sketch, the function can be rewritten as sum of two functions, one dependent on $\symPoissonRate_\symSetASuffix$ and the other dependent on $(\symPoissonRate_\symSetBSuffix+\symPoissonRate_\symSetXSuffix)$. 
The maximum is obtained, if $\symPoissonRate_\symSetASuffix = \symPoissonRateEstimate_1$ and $\symPoissonRate_\symSetBSuffix+\symPoissonRate_\symSetXSuffix = \symPoissonRateEstimate_2$. Here $\symPoissonRateEstimate_1$ and $\symPoissonRateEstimate_2$ are the cardinality estimates for the first and second HyperLogLog sketch, respectively. Similarly, if all register values of the first are smaller than those of the second HyperLogLog sketch, the maximum is obtained when 
$\symPoissonRate_\symSetASuffix+\symPoissonRate_\symSetXSuffix = \symPoissonRateEstimate_1$ and $\symPoissonRate_\symSetBSuffix = \symPoissonRateEstimate_2$.

If we know that the two HyperLogLog sketches have been filled by elements taken from disjoint sets we can assume $\symPoissonRate_\symSetXSuffix=0$. In this case \eqref{equ:log_likelihood_pair} is separable into the sum of two log-likelihood functions that depend on $\symPoissonRate_\symSetASuffix$ and $\symPoissonRate_\symSetBSuffix$, respectively, and that follow \eqref{equ:log_likelihood_single}. Hence, the joint maximum likelihood estimation of $\symPoissonRate_\symSetASuffix$ and $\symPoissonRate_\symSetBSuffix$ gives the same results as estimating them independently by maximizing \eqref{equ:log_likelihood_single}.

The first derivatives are
\begin{align}
\frac{\partial\log \symLikelihood}{\partial\symPoissonRate_\symSetASuffix}
(
\symPoissonRate_\symSetASuffix,
\symPoissonRate_\symSetBSuffix,
\symPoissonRate_\symSetXSuffix
\vert
\vec{\symRegVal}_1,
\vec{\symRegVal}_2
)
=
&
-
\frac{1}{\symNumReg}
\sum_{\symRegVal=0}^{\symRegRange}
\frac{
  \symCount^\leftarrow_\symRegVal+
  \symCount_{\symRegVal\symRegVal}+
  \symCount^\rightarrow_\symRegVal
}{2^{\symRegVal}}
+
\frac{1}{\symNumReg}
\sum_{\symRegVal=1}^{\symRegRange+1}
\frac{1}{e^{\frac{\symPoissonRate_\symSetASuffix+\symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}-1}
\frac{\symCount^\rightarrow_\symRegVal}{2^{\min\left(\symRegVal,\symRegRange\right)}}
\nonumber\\
&
+
\frac{1}{\symNumReg}\sum_{\symRegVal=1}^{\symRegRange+1}
\frac{1}{e^{\frac{\symPoissonRate_\symSetASuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}-1}
\frac{\symCount^\leftarrow_\symRegVal}{2^{\min\left(\symRegVal,\symRegRange\right)}}
\nonumber\\
&
+
\frac{1}{\symNumReg}
\sum_{\symRegVal=1}^{\symRegRange+1}
\frac{
e^{\frac{\symPoissonRate_\symSetBSuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}
-
1
}{
e^{\frac{\symPoissonRate_\symSetASuffix+\symPoissonRate_\symSetBSuffix+\symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}
-
e^{\frac{\symPoissonRate_\symSetBSuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}
-
e^{\frac{\symPoissonRate_\symSetASuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}
+
1
}
\frac{\symCount_{\symRegVal\symRegVal}
}{2^{\min\left(\symRegVal,\symRegRange\right)}}
\end{align}

\begin{align}
\frac{\partial\log \symLikelihood}{\partial\symPoissonRate_\symSetXSuffix}
(
\symPoissonRate_\symSetASuffix,
\symPoissonRate_\symSetBSuffix,
\symPoissonRate_\symSetXSuffix
\vert
\vec{\symRegVal}_1,
\vec{\symRegVal}_2
)
=
&
-
\frac{1}{\symNumReg}
\sum_{\symRegVal=0}^{\symRegRange}
\frac{
  \symCount^\rightarrow_\symRegVal+
  \symCount_{\symRegVal\symRegVal}+
  \symCount^\downarrow_\symRegVal
}{2^{\symRegVal}}
+
\frac{1}{\symNumReg}
\sum_{\symRegVal=1}^{\symRegRange+1}
\frac{1}{e^{\frac{\symPoissonRate_\symSetASuffix+\symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}-1}
\frac{\symCount^\rightarrow_\symRegVal}{2^{\min\left(\symRegVal,\symRegRange\right)}}
\nonumber\\
&
+
\frac{1}{\symNumReg}\sum_{\symRegVal=1}^{\symRegRange+1}
\frac{1}{e^{\frac{\symPoissonRate_\symSetBSuffix+\symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}-1}
\frac{\symCount^\downarrow_\symRegVal}{2^{\min\left(\symRegVal,\symRegRange\right)}}
\nonumber\\
&
+
\frac{1}{\symNumReg}
\sum_{\symRegVal=1}^{\symRegRange+1}
\frac{
e^{\frac{\symPoissonRate_\symSetASuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}
+
e^{\frac{\symPoissonRate_\symSetBSuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}
-
1
}{
e^{\frac{\symPoissonRate_\symSetASuffix+\symPoissonRate_\symSetBSuffix+\symPoissonRate_\symSetXSuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}
-
e^{\frac{\symPoissonRate_\symSetBSuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}
-
e^{\frac{\symPoissonRate_\symSetASuffix}{\symNumReg 2^{\min\left(\symRegVal,\symRegRange\right)}}}
+
1
}
\frac{\symCount_{\symRegVal\symRegVal}
}{2^{\min\left(\symRegVal,\symRegRange\right)}}
\end{align}


\subsection{Results}

TODO


\section{Conclusion and future work}

TODO

\appendix

\section{Numerical stability of recursion formula for $\symHelper(\symX)$}
\label{app:helper_stable}
In order to investigate the error propagation of a single recursion step using \eqref{equ:helper_recursion1} we define $\symHelper_1 := \symHelper(\symX)$ and $\symHelper_2 := \symHelper(2\symX)$. The recursion formula simplifies to
\begin{equation}
\label{equ:h2}
\symHelper_2 = \frac{\symX+2\symHelper_1(1-\symHelper_1)}{\symX+2(1-\symHelper_1)}.
\end{equation}
If $\symHelper_1$ is approximated by $\tilde{\symHelper}_1 = \symHelper_1\left(1+\symError_1\right)$ with relative error $\symError_1$, the recursion formula will give an approximation for $\symHelper_2$
\begin{equation}
\label{equ:h2_approx}
\tilde{\symHelper}_2 = 
\frac{\symX+2\tilde{\symHelper}_1(1-\tilde{\symHelper}_1)}{\symX+2(1-\tilde{\symHelper_1})}
\end{equation}
The corresponding relative error $\symError_2$ is given by
\begin{equation}
\label{equ:h2_relative_error}
\symError_2 = \frac{\tilde{\symHelper}_2}{\symHelper_2}-1.
\end{equation}
Putting \eqref{equ:h2} and \eqref{equ:h2_approx} into \eqref{equ:h2_relative_error} and using the first-order approximations 
\begin{equation}
\frac{\symX+2\tilde{\symHelper}_1(1-\tilde{\symHelper}_1)}
{\symX+2\symHelper_1(1-\symHelper_1)}
=
1
+
\symError_1
\frac{2\symHelper_1\left(1-2\symHelper_1\right)}
{\symX + 2\symHelper_1\left(1-\symHelper_1\right)}
+\symBigO(\symError_1^2)
\end{equation}
and
\begin{equation}
\frac{\symX+2(1-\symHelper_1)}
{\symX+2(1-\tilde{\symHelper}_1)}
=
1
+
\symError_1
\frac{2\symHelper_1}{x+2\left(1-\symHelper_1\right)}
+\symBigO(\symError_1^2),
\end{equation}
we obtain
\begin{equation}
\symError_2
=
\symError_1
\left(
\frac{2\symHelper_1\left(1-2\symHelper_1\right)}
{\symX + 2\symHelper_1\left(1-\symHelper_1\right)}
+
\frac{2\symHelper_1}{x+2\left(1-\symHelper_1\right)}
\right)
+\symBigO(\symError_1^2)
\end{equation}
By numerical means it is easy to show that
\begin{equation}
0\leq\frac{2\symHelper(\symX)\left(1-2\symHelper(\symX)\right)}
{\symX + 2\symHelper(\symX)\left(1-\symHelper(\symX)\right)}
+
\frac{2\symHelper(\symX)}{x+2\left(1-\symHelper(\symX)\right)} \leq \input{max_errror_propagation_factor.txt}
\end{equation}
holds for all $\symX \geq 0$. Therefore,
\begin{equation}
|\symError_2|\leq \input{max_errror_propagation_factor.txt}\  |\symError_1| + \symBigO(\symError_1^2)
\end{equation}
which means that the relative error is decreasing in each recursion step and the recursive calculation of $\symHelper$ is numerically stable.

\section{Error caused by approximation of $\symHelper(\symX)$}
According to \eqref{equ:func} the exact estimate $\symXEstimate$ fulfills 
\begin{equation}
\label{equ:max_likelihood_2}
\symXEstimate\sum_{\symRegVal=0}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}+
\sum_{\symRegVal=1}^\symRegRange \symCount_\symRegVal\symHelper\left(\frac{\symXEstimate}{2^\symRegVal}\right)
+
\symCount_{\symRegRange+1}\symHelper\left(\frac{\symXEstimate}{2^\symRegRange}\right)
=
\symNumReg-\symCount_0
\end{equation}
If $\symHelper$ is not calculated exactly but approximated by an approximation $\symHelperApprox$ with maximum relative error $\symError_\symHelper\ll 1$
\begin{equation}
\label{equ:abs_error_helper}
\left|\symHelperApprox(\symX) - \symHelper(\symX) \right|  \leq \symError_\symHelper\symHelper(\symX)
\end{equation}
the solution of the equation will be off by a relative error $\symError_\symX$:
\begin{equation}
\label{equ:ml_equation}
\symXEstimate\left(1+\symError_\symX\right)\sum_{\symRegVal=0}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}+
\sum_{\symRegVal=1}^\symRegRange \symCount_\symRegVal\symHelperApprox\left(\frac{\symXEstimate\left(1+\symError_\symX\right)}{2^\symRegVal}\right)
+
\symCount_{\symRegRange+1}
\symHelperApprox\left(
\frac{\symXEstimate\left(1+\symError_\symX\right)}{2^\symRegRange}\right)
=
\symNumReg-\symCount_0
\end{equation}
Due to \eqref{equ:abs_error_helper} there exists some $\symAlpha \in [-\symError_\symHelper, \symError_\symHelper]$ for which
\begin{multline}
\symXEstimate\left(1+\symError_\symX\right)\sum_{\symRegVal=0}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}+
\left(
1+\symAlpha
\right)
\left(
\sum_{\symRegVal=1}^\symRegRange \symCount_\symRegVal
\symHelper\left(\frac{\symXEstimate\left(1+\symError_\symX\right)
}{2^\symRegVal}\right)
+
\symCount_{\symRegRange+1}
\symHelper\left(
\frac{\symXEstimate\left(1+\symError_\symX\right)}{2^\symRegRange}\right)
\right)
=
\symNumReg-\symCount_0
\end{multline}
For $\symX \geq 0$ $\symHelper'(\symX)\in[0,0.5]$. Hence, there exists a $\symBeta\in[0,0.5]$ for which
\begin{multline}
\label{equ:appendix3}
\symXEstimate\left(1+\symError_\symX\right)\sum_{\symRegVal=0}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}+
\left(
1+\symAlpha
\right)
\left(
\sum_{\symRegVal=1}^\symRegRange 
\symCount_\symRegVal
\symHelper\left(\frac{\symXEstimate
}{2^\symRegVal}\right)
+
\frac{\symCount_\symRegVal}{2^\symRegVal}
\symXEstimate\symError_\symX
\symBeta
\right)
+
\\
+
\left(
1+\symAlpha
\right)
\left(
\symCount_{\symRegRange+1}
\symHelper\left(
\frac{\symXEstimate}{2^\symRegRange}\right)
+
\frac{\symCount_{\symRegRange+1}}{2^\symRegRange}
\symXEstimate\symError_\symX\symBeta
\right)
=
\symNumReg-\symCount_0
\end{multline}
Subtracting \eqref{equ:max_likelihood_2} multiplied by $\left(1+\symAlpha\right)$ from \eqref{equ:appendix3} and resolving 
$\symError_\symX$ gives
\begin{equation}
\symError_\symX
=
\symAlpha
\frac{
\symXEstimate
\sum_{\symRegVal=0}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}
-\left(\symNumReg-\symCount_0\right)
}
{
\symXEstimate
\left(
\sum_{\symRegVal=0}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}
+
\left(1+\symAlpha\right)
\symBeta
\left(
\sum_{\symRegVal=1}^\symRegRange 
\frac{\symCount_\symRegVal
}{2^\symRegVal}
+
\frac{\symCount_{\symRegRange+1}
}{2^\symRegRange}
\right)
\right)
}
\end{equation}
Using $\left|\symAlpha\right|\leq\symError_\symHelper$, $\symBeta\geq0$, and \eqref{equ:weak_upper_bound} the absolute value of the relative error
can be bounded by
\begin{equation}
\left|\symError_\symX\right| 
\leq
\left|\symError_\symHelper\right| 
\frac{
\left(\symNumReg-\symCount_0\right)-
\symXEstimate
\sum_{\symRegVal=0}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}
}
{
\symXEstimate
\sum_{\symRegVal=0}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}
}
\end{equation}
Furthermore, using \eqref{equ:weak_lower_bound} we finally get
\begin{equation}
\left|\symError_\symX\right| 
\leq
\left|\symError_\symHelper\right|
\frac{
\frac{1}{2}
\sum_{\symRegVal=1}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}
+
\frac{\symCount_{\symRegRange+1}
}{2^\symRegRange}
}
{
\sum_{\symRegVal=0}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}
}
\leq
\left|\symError_\symHelper\right|
\left(
\frac{1}{2}
+
\frac{
\frac{\symCount_{\symRegRange+1}
}{2^\symRegRange}
}
{
\sum_{\symRegVal=1}^\symRegRange \frac{\symCount_\symRegVal}{2^\symRegVal}
}
\right)
\leq
\left|\symError_\symHelper\right|
\left(
\frac{1}{2}
+
\frac{
\symCount_{\symRegRange+1}
}
{
\symNumReg-\symCount_{\symRegRange+1}
}
\right)
\end{equation}
Hence, as long as most registers are not in the saturated state ($\symCount_{\symRegRange+1}\ll\symNumReg$), the relative error $\symError_\symX$ of the calculated estimate using the approximation $\symHelperApprox(\symX)$ for $\symHelper(\symX)$ has the same order of magnitude as $\symError_\symHelper$.

% TODO is it possible to prove 
%$\left|\symError_\symX\right| 
%\leq
%\left|\symError_\symHelper\right|
%\frac{1}{2}
%\frac{
%\symNumReg
%}
%{
%\symNumReg-\symCount_{\symRegRange+1}
%}
%$}

\bibliographystyle{unsrt}
\bibliography{bibliography.bib}

\end{document}



 

 
